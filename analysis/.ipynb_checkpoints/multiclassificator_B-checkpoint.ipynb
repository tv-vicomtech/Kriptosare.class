{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = 'pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/opt/spark')\n",
    "from pyspark import SparkContext,SparkConf\n",
    "conf = (SparkConf()\n",
    "         .setMaster(\"spark://10.200.5.39:7077\")\n",
    "         .set(\"spark.executor.memory\",\"30g\")\n",
    "         .set(\"spark.sql.autoBroadcastJoinThreshold\", \"-1\")\n",
    "         .setAppName(\"Classification\"))\n",
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import binascii\n",
    "from pyspark.sql import SQLContext\n",
    "from functools import reduce\n",
    "from sklearn import tree\n",
    "from pyspark.sql.types import *\n",
    "import pygraphviz\n",
    "import pyspark.sql.functions as f\n",
    "import networkx as nx\n",
    "from networkx.readwrite import json_graph\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import AdaBoostClassifier,RandomForestClassifier\n",
    "from sklearn import datasets,metrics\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from IPython.display import Image\n",
    "from networkx.drawing.nx_pydot import write_dot\n",
    "import pickle\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"hdfs://10.200.5.25:9001/user/titanium/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_label_to_id(df,new_col,old_col):\n",
    "    df = df.withColumn(new_col,f.when(f.col(old_col).like(\"b%\"),0).otherwise(f.col(old_col)))\n",
    "    df = df.withColumn(new_col,f.when(f.col(old_col).like(\"e%\"),1).otherwise(f.col(new_col)))\n",
    "    df = df.withColumn(new_col,f.when(f.col(old_col).like(\"c%\"),2).otherwise(f.col(new_col)))\n",
    "    df = df.withColumn(new_col,f.when(f.col(old_col).like(\"o%\"),3).otherwise(f.col(new_col)))\n",
    "    df = df.withColumn(new_col,f.when(f.col(old_col).like(\"Coin%\"),3).otherwise(f.col(new_col)))\n",
    "    return df\n",
    "\n",
    "def change_label_new_df(df,new_col,old_col,t):\n",
    "    df = df.withColumn(new_col,f.when(f.col(old_col).like(\"b%\"),f.concat(f.lit(t*\"b\"),f.col(old_col))).otherwise(f.col(old_col)))\n",
    "    df = df.withColumn(new_col,f.when(f.col(old_col).like(\"e%\"),f.concat(f.lit(t*\"e\"),f.col(old_col))).otherwise(f.col(new_col)))\n",
    "    df = df.withColumn(new_col,f.when(f.col(old_col).like(\"c%\"),f.concat(f.lit(t*\"c\"),f.col(old_col))).otherwise(f.col(new_col)))\n",
    "    df = df.withColumn(new_col,f.when(f.col(old_col).like(\"o%\"),f.concat(f.lit(t*\"o\"),f.col(old_col))).otherwise(f.col(new_col)))\n",
    "    return df\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"label\", StringType(), True),\n",
    "    StructField(\"user\", StringType(), True),\n",
    "])\n",
    "\n",
    "def join_dataframe_intag(DF,pref):\n",
    "    DF=DF.groupBy(\"user\").agg(f.collect_list(\"label\").alias(\"list\"))\n",
    "    DF = DF.select(\"user\",f.explode(\"list\").alias(\"value\")).groupBy(\"user\",\"value\").agg(f.count(\"value\").alias(\"cnt\"))\n",
    "    DF2 = DF.groupBy(\"user\").agg(f.count(\"user\").alias(\"cnt\")).drop(\"cnt\")\n",
    "    DF2 = DF2.alias(\"a\").join(DF.alias('b'),(f.col(\"a.user\")==f.col(\"b.user\")) & (f.col(\"b.value\")==0),\"leftouter\").select(\"a.user\",\"b.cnt\").withColumnRenamed(\"cnt\",pref+\"_cnt0\")\n",
    "    DF2 = DF2.alias(\"a\").join(DF.alias('b'),(f.col(\"a.user\")==f.col(\"b.user\")) & (f.col(\"b.value\")==1),\"leftouter\").select(\"a.user\",pref+\"_cnt0\",\"b.cnt\").withColumnRenamed(\"cnt\",pref+\"_cnt1\")\n",
    "    DF2 = DF2.alias(\"a\").join(DF.alias('b'),(f.col(\"a.user\")==f.col(\"b.user\")) & (f.col(\"b.value\")==2),\"leftouter\").select(\"a.user\",pref+\"_cnt0\",pref+\"_cnt1\",\"b.cnt\").withColumnRenamed(\"cnt\",pref+\"_cnt2\")\n",
    "    DF2 = DF2.alias(\"a\").join(DF.alias('b'),(f.col(\"a.user\")==f.col(\"b.user\")) & (f.col(\"b.value\")==3),\"leftouter\").select(\"a.user\",pref+\"_cnt0\",pref+\"_cnt1\",pref+\"_cnt2\",\"b.cnt\").withColumnRenamed(\"cnt\",pref+\"_cnt3\")\n",
    "\n",
    "    DF2=DF2.fillna(0)\n",
    "    return DF2\n",
    "\n",
    "def link_outclass_intag(user,b):\n",
    "    dd = [(user[i][0], int(b[i])) for i in range(len(user))]\n",
    "    df = sqlContext.createDataFrame(sc.parallelize(dd),schema=[\"user\", \"label\"])\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Definition\n",
    "# 0: user\n",
    "# 1: exchange\n",
    "# 2: casino\n",
    "# 3: coinbase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "syntethic_directory=\"synthetic_data/dataframe_exported/data160119/\"\n",
    "\n",
    "entity_d1= sqlContext.read.format('com.databricks.spark.csv')\\\n",
    ".options(header='true',inferSchema='true')\\\n",
    ".load(path+syntethic_directory+\"entity_feature/\")\n",
    "\n",
    "address_d1 = sqlContext.read.format('com.databricks.spark.csv')\\\n",
    ".options(header='true',inferSchema='true')\\\n",
    ".load(path+syntethic_directory+\"address_feature/\")\n",
    "\n",
    "motif1_d1 = sqlContext.read.format('com.databricks.spark.csv')\\\n",
    ".options(header='true',inferSchema='true')\\\n",
    ".load(path+syntethic_directory+\"motifs_1/\")\n",
    "\n",
    "motif2_d1 = sqlContext.read.format('com.databricks.spark.csv')\\\n",
    ".options(header='true',inferSchema='true')\\\n",
    ".load(path+syntethic_directory+\"motifs_2/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_directory=\"synthetic_data/dataframe_exported/data290119/\"\n",
    "\n",
    "entity_d2= sqlContext.read.format('com.databricks.spark.csv')\\\n",
    ".options(header='true',inferSchema='true')\\\n",
    ".load(path+syntethic_directory+\"entity_feature/\")\n",
    "\n",
    "address_d2 = sqlContext.read.format('com.databricks.spark.csv')\\\n",
    ".options(header='true',inferSchema='true')\\\n",
    ".load(path+syntethic_directory+\"address_feature/\")\n",
    "\n",
    "motif1_d2 = sqlContext.read.format('com.databricks.spark.csv')\\\n",
    ".options(header='true',inferSchema='true')\\\n",
    ".load(path+syntethic_directory+\"motifs_1/\")\n",
    "\n",
    "motif2_d2 = sqlContext.read.format('com.databricks.spark.csv')\\\n",
    ".options(header='true',inferSchema='true')\\\n",
    ".load(path+syntethic_directory+\"motifs_2/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_directory=\"synthetic_data/dataframe_exported/data310119/\"\n",
    "\n",
    "entity_d3= sqlContext.read.format('com.databricks.spark.csv')\\\n",
    ".options(header='true',inferSchema='true')\\\n",
    ".load(path+syntethic_directory+\"entity_feature/\")\n",
    "\n",
    "address_d3 = sqlContext.read.format('com.databricks.spark.csv')\\\n",
    ".options(header='true',inferSchema='true')\\\n",
    ".load(path+syntethic_directory+\"address_feature/\")\n",
    "\n",
    "motif1_d3 = sqlContext.read.format('com.databricks.spark.csv')\\\n",
    ".options(header='true',inferSchema='true')\\\n",
    ".load(path+syntethic_directory+\"motifs_1/\")\n",
    "\n",
    "motif2_d3 = sqlContext.read.format('com.databricks.spark.csv')\\\n",
    ".options(header='true',inferSchema='true')\\\n",
    ".load(path+syntethic_directory+\"motifs_2/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "#               REDEFINITION SOME LABEL (AVOID OVERLAP TAG)\n",
    "####################################################################\n",
    "\n",
    "entity_d2 = change_label_new_df(entity_d2,\"user\",\"user\",1)\n",
    "address_d2 = change_label_new_df(address_d2,\"user\",\"user\",1)\n",
    "motif1_d2 = change_label_new_df(motif1_d2,\"outuser\",\"outuser\",1)\n",
    "motif1_d2 = change_label_new_df(motif1_d2,\"inuser\",\"inuser\",1)\n",
    "motif2_d2 = change_label_new_df(motif2_d2,\"outuser\",\"outuser\",1)\n",
    "motif2_d2 = change_label_new_df(motif2_d2,\"miduser\",\"miduser\",1)\n",
    "motif2_d2 = change_label_new_df(motif2_d2,\"inuser\",\"inuser\",1)\n",
    "\n",
    "entity_d3 = change_label_new_df(entity_d3,\"user\",\"user\",2)\n",
    "address_d3 = change_label_new_df(address_d3,\"user\",\"user\",2)\n",
    "motif1_d3 = change_label_new_df(motif1_d3,\"outuser\",\"outuser\",2)\n",
    "motif1_d3 = change_label_new_df(motif1_d3,\"inuser\",\"inuser\",2)\n",
    "motif2_d3 = change_label_new_df(motif2_d3,\"outuser\",\"outuser\",2)\n",
    "motif2_d3 = change_label_new_df(motif2_d3,\"miduser\",\"miduser\",2)\n",
    "motif2_d3 = change_label_new_df(motif2_d3,\"inuser\",\"inuser\",2)\n",
    "\n",
    "####################################################################\n",
    "#               JOIN DATAFRAME\n",
    "####################################################################\n",
    "entity_data1 = entity_d1.union(entity_d2)\n",
    "address_data1= address_d1.union(address_d2)\n",
    "motif1_data1 = motif1_d1.union(motif1_d2)\n",
    "motif2_data1 = motif2_d1.union(motif2_d2)\n",
    "\n",
    "entity_data1 = entity_data1.union(entity_d3)\n",
    "address_data1= address_data1.union(address_d3)\n",
    "motif1_data1 = motif1_data1.union(motif1_d3)\n",
    "motif2_data1 = motif2_data1.union(motif2_d3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "#               ENTITY ML\n",
    "####################################################################\n",
    "\n",
    "entity_feature = entity_data1.filter(f.col(\"user\")!=\"Unknow\").fillna(0)\n",
    "\n",
    "#Transform label to class index \n",
    "entity_feature=transform_label_to_id(entity_feature,\"label\",\"user\")\n",
    "\n",
    "df_entity=entity_feature.randomSplit([0.7,0.3])\n",
    "\n",
    "#Split the input and the output from dataframe \n",
    "ent_X=df_entity[0].select(\"balance_recv\",\"balancein\",\"balance\",\"count_recv\",\"count_sent\",\"add_out\",\"add_in\")\n",
    "ent_y=df_entity[0].select(\"label\")\n",
    "#Round amount field\n",
    "ent_X = ent_X.withColumn(\"balance_recv\", f.round(ent_X[\"balance_recv\"], 6))\n",
    "ent_X = ent_X.withColumn(\"balancein\", f.round(ent_X[\"balancein\"], 6))\n",
    "ent_X = ent_X.withColumn(\"balance\", f.round(ent_X[\"balance\"], 6))\n",
    "\n",
    "#Transform input/output dataframe in vector\n",
    "X_train_ent= ent_X.collect()\n",
    "y_train_ent = ent_y.collect()\n",
    "\n",
    "#Reshape the output vector\n",
    "y_train_ent=np.reshape(y_train_ent,(len(y_train_ent),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the input and the output from dataframe \n",
    "ent_X=df_entity[1].select(\"balance_recv\",\"balancein\",\"balance\",\"count_recv\",\"count_sent\",\"add_out\",\"add_in\")\n",
    "ent_y=df_entity[1].select(\"label\")\n",
    "#Round amount field\n",
    "ent_X = ent_X.withColumn(\"balance_recv\", f.round(ent_X[\"balance_recv\"], 6))\n",
    "ent_X = ent_X.withColumn(\"balancein\", f.round(ent_X[\"balancein\"], 6))\n",
    "ent_X = ent_X.withColumn(\"balance\", f.round(ent_X[\"balance\"], 6))\n",
    "\n",
    "#Transform input/output dataframe in vector\n",
    "X_test_ent= ent_X.collect()\n",
    "y_test_ent = ent_y.collect()\n",
    "\n",
    "y_test_ent=np.reshape(y_test_ent,(len(y_test_ent),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "####################################################################\n",
    "#               ADABOOST ML\n",
    "####################################################################\n",
    "\n",
    "#Create adaboost classifer object\n",
    "abc_ent = AdaBoostClassifier(n_estimators=50,learning_rate=1)\n",
    "\n",
    "#Train Adaboost Classifer\n",
    "adaboost_ent = abc_ent.fit(X_train_ent, y_train_ent)\n",
    "\n",
    "####################################################################\n",
    "#               RANDOM FOREST ML\n",
    "####################################################################\n",
    "\n",
    "#Create random forest classifer object\n",
    "rfc_ent= RandomForestClassifier(n_jobs=2, random_state=0)\n",
    "\n",
    "#Train Randomforest Classifer\n",
    "randomforest_ent=rfc_ent.fit(X_train_ent, y_train_ent)\n",
    "\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "model_nb = GaussianNB()\n",
    "model_nb_ent=model_nb.fit(X_train_ent,y_train_ent)\n",
    "\n",
    "model_knn = KNeighborsClassifier(n_neighbors=7)\n",
    "modelknn_ent=model_knn.fit(X_train_ent,y_train_ent)\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(13,13,13),max_iter=500)\n",
    "mlp_ent=mlp.fit(X_train_ent,y_train_ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###################################\n",
      "Train=834; Test=366;  Accuracy Adaboost:1.0\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       306\n",
      "           1       1.00      1.00      1.00        36\n",
      "           2       1.00      1.00      1.00        24\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       366\n",
      "   macro avg       1.00      1.00      1.00       366\n",
      "weighted avg       1.00      1.00      1.00       366\n",
      "\n",
      "Train=834; Test=366;  Accuracy RandomForest:0.9918032786885246\n",
      "0.9725002488924304\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       306\n",
      "           1       1.00      1.00      1.00        36\n",
      "           2       0.89      1.00      0.94        24\n",
      "\n",
      "   micro avg       0.99      0.99      0.99       366\n",
      "   macro avg       0.96      1.00      0.98       366\n",
      "weighted avg       0.99      0.99      0.99       366\n",
      "\n",
      "Train=834; Test=366;  Accuracy KNN:0.9890710382513661\n",
      "0.9636880142409209\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       306\n",
      "           1       0.97      1.00      0.99        36\n",
      "           2       0.89      1.00      0.94        24\n",
      "\n",
      "   micro avg       0.99      0.99      0.99       366\n",
      "   macro avg       0.95      1.00      0.97       366\n",
      "weighted avg       0.99      0.99      0.99       366\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Predict the response for test dataset\n",
    "y_ent_prediction_ada = adaboost_ent.predict(X_test_ent)\n",
    "y_ent_prediction_rf = randomforest_ent.predict(X_test_ent) \n",
    "y_ent_prediction_knn = modelknn_ent.predict(X_test_ent) \n",
    "y_ent_prediction_mlp = mlp_ent.predict(X_test_ent) \n",
    "y_ent_prediction_nb = model_nb_ent.predict(X_test_ent) \n",
    "\n",
    "#Accuracy with the same dataset\n",
    "print(\"###################################\")\n",
    "print(\"Train=%s; Test=%s;  Accuracy Adaboost:%s\" %(len(X_train_ent),len(X_test_ent),metrics.accuracy_score(y_test_ent, y_ent_prediction_ada)))\n",
    "print(matthews_corrcoef(y_test_ent,y_ent_prediction_ada))\n",
    "print(classification_report(y_test_ent,y_ent_prediction_ada))\n",
    "print(\"Train=%s; Test=%s;  Accuracy RandomForest:%s\" %(len(X_train_ent),len(X_test_ent),metrics.accuracy_score(y_test_ent, y_ent_prediction_rf)))\n",
    "print(matthews_corrcoef(y_test_ent,y_ent_prediction_rf))\n",
    "print(classification_report(y_test_ent,y_ent_prediction_rf))\n",
    "print(\"Train=%s; Test=%s;  Accuracy KNN:%s\" %(len(X_train_ent),len(X_test_ent),metrics.accuracy_score(y_test_ent, y_ent_prediction_knn)))\n",
    "print(matthews_corrcoef(y_test_ent,y_ent_prediction_knn))\n",
    "print(classification_report(y_test_ent,y_ent_prediction_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "#               ADDRESS ML\n",
    "####################################################################\n",
    "\n",
    "address_data1 = address_data1.filter(f.col(\"user\")!=\"Unknow\")\n",
    "\n",
    "#Transform label to class index \n",
    "address_feature=transform_label_to_id(address_data1,\"label\",\"user\")\n",
    "\n",
    "df_address=address_feature.randomSplit([0.7,0.3])\n",
    "\n",
    "#Split the input and the output from dataframe \n",
    "add_X=df_address[0].select(\"count_rec\",\"totamount_rec\",\"count_sent\",\"totamount_sent\",\"balance\",\"unique\",\"sibling\")\n",
    "add_y=df_address[0].select(\"label\")\n",
    "#Round amount field\n",
    "add_X = add_X.withColumn(\"totamount_rec\", f.round(add_X[\"totamount_rec\"], 6))\n",
    "add_X = add_X.withColumn(\"totamount_sent\", f.round(add_X[\"totamount_sent\"], 6))\n",
    "add_X = add_X.withColumn(\"balance\", f.round(add_X[\"balance\"], 6))\n",
    "\n",
    "#Transform input/output dataframe in vector\n",
    "X_train_add = add_X.collect()\n",
    "y_train_add = add_y.collect()\n",
    "\n",
    "#Reshape the output vector\n",
    "y_train_add=np.reshape(y_train_add,(len(y_train_add),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the input and the output from dataframe \n",
    "add_X=df_address[1].select(\"count_rec\",\"totamount_rec\",\"count_sent\",\"totamount_sent\",\"balance\",\"unique\",\"sibling\")\n",
    "add_y=df_address[1].select(\"label\")\n",
    "#Round amount field\n",
    "add_X = add_X.withColumn(\"totamount_rec\", f.round(add_X[\"totamount_rec\"], 6))\n",
    "add_X = add_X.withColumn(\"totamount_sent\", f.round(add_X[\"totamount_sent\"], 6))\n",
    "add_X = add_X.withColumn(\"balance\", f.round(add_X[\"balance\"], 6))\n",
    "\n",
    "#Transform input/output dataframe in vector\n",
    "X_test_add = add_X.collect()\n",
    "y_test_add = add_y.collect()\n",
    "\n",
    "#Reshape the output vector\n",
    "y_test_add=np.reshape(y_test_add,(len(y_test_add),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "####################################################################\n",
    "#               ADABOOST ML\n",
    "####################################################################\n",
    "\n",
    "#Create adaboost classifer object\n",
    "abc_add = AdaBoostClassifier(n_estimators=50,learning_rate=1)\n",
    "\n",
    "#Train Adaboost Classifer\n",
    "adaboost_add = abc_add.fit(X_train_add, y_train_add)\n",
    "\n",
    "####################################################################\n",
    "#               RANDOM FOREST ML\n",
    "####################################################################\n",
    "\n",
    "#Create random forest classifer object\n",
    "rfc_add= RandomForestClassifier(n_jobs=2, random_state=0)\n",
    "\n",
    "#Train Randomforest Classifer\n",
    "randomforest_add=rfc_add.fit(X_train_add, y_train_add)\n",
    "\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "model_nb = GaussianNB()\n",
    "model_nb_add=model_nb.fit(X_train_add, y_train_add)\n",
    "\n",
    "model_knn = KNeighborsClassifier(n_neighbors=7)\n",
    "modelknn_add=model_knn.fit(X_train_add, y_train_add)\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(13,13,13),max_iter=500)\n",
    "mlp_add=mlp.fit(X_train_add, y_train_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset = Test dataset\n",
      "Train=92695; Test=39788;  Accuracy Adaboost:0.8948175329244998\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94     35660\n",
      "           1       0.37      0.07      0.12      2806\n",
      "           2       0.94      0.07      0.12      1322\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     39788\n",
      "   macro avg       0.74      0.38      0.39     39788\n",
      "weighted avg       0.87      0.89      0.86     39788\n",
      "\n",
      "Train=92695; Test=39788;  Accuracy RandomForest:0.9654167085553433\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98     35660\n",
      "           1       0.85      0.79      0.82      2806\n",
      "           2       0.87      0.76      0.81      1322\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     39788\n",
      "   macro avg       0.90      0.85      0.87     39788\n",
      "weighted avg       0.96      0.97      0.96     39788\n",
      "\n",
      "Train=92695; Test=39788;  Accuracy KNN:0.8992912435910325\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95     35660\n",
      "           1       0.50      0.23      0.31      2806\n",
      "           2       0.52      0.14      0.22      1322\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     39788\n",
      "   macro avg       0.64      0.45      0.49     39788\n",
      "weighted avg       0.87      0.90      0.88     39788\n",
      "\n",
      "Train=92695; Test=39788;  Accuracy MLP:0.8976575852015684\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.14      0.25     35660\n",
      "           1       0.14      0.28      0.19      2806\n",
      "           2       0.04      0.88      0.08      1322\n",
      "\n",
      "   micro avg       0.18      0.18      0.18     39788\n",
      "   macro avg       0.39      0.43      0.17     39788\n",
      "weighted avg       0.91      0.18      0.24     39788\n",
      "\n",
      "Train=92695; Test=39788;  Accuracy NB:0.17548004423444255\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.14      0.25     35660\n",
      "           1       0.14      0.28      0.19      2806\n",
      "           2       0.04      0.88      0.08      1322\n",
      "\n",
      "   micro avg       0.18      0.18      0.18     39788\n",
      "   macro avg       0.39      0.43      0.17     39788\n",
      "weighted avg       0.91      0.18      0.24     39788\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Predict the response for test dataset\n",
    "y_add_prediction_ada = adaboost_add.predict(X_test_add)\n",
    "y_add_prediction_rf = randomforest_add.predict(X_test_add) \n",
    "y_add_prediction_knn = modelknn_add.predict(X_test_add) \n",
    "y_add_prediction_mlp = mlp_add.predict(X_test_add) \n",
    "y_add_prediction_nb = model_nb_add.predict(X_test_add) \n",
    "\n",
    "#Accuracy with the same dataset\n",
    "print(\"Train dataset = Test dataset\")\n",
    "print(\"Train=%s; Test=%s;  Accuracy Adaboost:%s\" %(len(X_train_add),len(X_test_add),metrics.accuracy_score(y_test_add, y_add_prediction_ada)))\n",
    "print(classification_report(y_test_add,y_add_prediction_ada))\n",
    "print(\"Train=%s; Test=%s;  Accuracy RandomForest:%s\" %(len(X_train_add),len(X_test_add),metrics.accuracy_score(y_test_add, y_add_prediction_rf)))\n",
    "print(classification_report(y_test_add,y_add_prediction_rf))\n",
    "print(\"Train=%s; Test=%s;  Accuracy KNN:%s\" %(len(X_train_add),len(X_test_add),metrics.accuracy_score(y_test_add, y_add_prediction_knn)))\n",
    "print(classification_report(y_test_add,y_add_prediction_knn))\n",
    "print(\"Train=%s; Test=%s;  Accuracy MLP:%s\" %(len(X_train_add),len(X_test_add),metrics.accuracy_score(y_test_add, y_add_prediction_mlp)))\n",
    "print(classification_report(y_test_add,y_add_prediction_nb))\n",
    "print(\"Train=%s; Test=%s;  Accuracy NB:%s\" %(len(X_train_add),len(X_test_add),metrics.accuracy_score(y_test_add, y_add_prediction_nb)))\n",
    "print(classification_report(y_test_add,y_add_prediction_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "#               MOTIFS-1 ML\n",
    "####################################################################\n",
    "\n",
    "motif1_feature=motif1_data1.withColumnRenamed(\"outuser\",\"user\")\n",
    "\n",
    "\n",
    "#Transform label to class index (input (?) and output)\n",
    "motif1_feature=transform_label_to_id(motif1_feature,\"label\",\"user\")\n",
    "motif1_feature=transform_label_to_id(motif1_feature,\"labelin\",\"inuser\")\n",
    "\n",
    "motif1_feature =motif1_feature.withColumn(\"labelin\", f.col(\"labelin\").cast(\"integer\"))\n",
    "\n",
    "df_motifs1=motif1_feature.randomSplit([0.7,0.3])\n",
    "\n",
    "#Split the input and the output from dataframe \n",
    "#mot1_X=df_motifs1[0].select(\"labelin\",\"address_recv_dist\",\"amount_recv\",\"tx_sent\",\"address_sent_dist\",\"amount_sent\",\"tx_recv_tot\",\"fees\",\"loop_in_out\",\"direct_in_out\")\n",
    "mot1_X=df_motifs1[0].select(\"address_recv_dist\",\"amount_recv\",\"tx_sent\",\"address_sent_dist\",\"amount_sent\",\"tx_recv_tot\",\"fees\",\"loop_in_out\",\"direct_in_out\")\n",
    "mot1_y=df_motifs1[0].select(\"label\")\n",
    "\n",
    "#Round amount field\n",
    "mot1_X = mot1_X.withColumn(\"amount_recv\", f.round(mot1_X[\"amount_recv\"], 6))\n",
    "mot1_X = mot1_X.withColumn(\"amount_sent\", f.round(mot1_X[\"amount_sent\"], 6))\n",
    "mot1_X = mot1_X.withColumn(\"fees\", f.round(mot1_X[\"fees\"], 6))\n",
    "\n",
    "#Transform input/output dataframe in vector\n",
    "X_train_mot1 = mot1_X.collect()\n",
    "y_train_mot1 = mot1_y.collect()\n",
    "\n",
    "#Reshape the output vector\n",
    "y_train_mot1=np.reshape(y_train_mot1,(len(y_train_mot1),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the input and the output from dataframe \n",
    "#mot1_X=df_motifs1[1].select(\"labelin\",\"address_recv_dist\",\"amount_recv\",\"tx_sent\",\"address_sent_dist\",\"amount_sent\",\"tx_recv_tot\",\"fees\",\"loop_in_out\",\"direct_in_out\")\n",
    "mot1_X=df_motifs1[1].select(\"address_recv_dist\",\"amount_recv\",\"tx_sent\",\"address_sent_dist\",\"amount_sent\",\"tx_recv_tot\",\"fees\",\"loop_in_out\",\"direct_in_out\")\n",
    "mot1_y=df_motifs1[1].select(\"label\")\n",
    "\n",
    "#Round amount field\n",
    "mot1_X = mot1_X.withColumn(\"amount_recv\", f.round(mot1_X[\"amount_recv\"], 6))\n",
    "mot1_X = mot1_X.withColumn(\"amount_sent\", f.round(mot1_X[\"amount_sent\"], 6))\n",
    "mot1_X = mot1_X.withColumn(\"fees\", f.round(mot1_X[\"fees\"], 6))\n",
    "\n",
    "#Transform input/output dataframe in vector\n",
    "X_test_mot1 = mot1_X.collect()\n",
    "y_test_mot1 = mot1_y.collect()\n",
    "\n",
    "#Reshape the output vector\n",
    "y_test_mot1=np.reshape(y_test_mot1,(len(y_test_mot1),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "####################################################################\n",
    "#               ADABOOST ML\n",
    "####################################################################\n",
    "\n",
    "# Create adaboost classifer object\n",
    "abc_mot1 = AdaBoostClassifier(n_estimators=50,learning_rate=1)\n",
    "\n",
    "# Train Adaboost Classifer\n",
    "adaboost_mot1 = abc_mot1.fit(X_train_mot1, y_train_mot1)\n",
    "\n",
    "####################################################################\n",
    "#               RANDOM FOREST ML\n",
    "####################################################################\n",
    "\n",
    "#Create random forest classifer object\n",
    "rfc_mot1= RandomForestClassifier(n_jobs=2, random_state=0)\n",
    "\n",
    "#Train Randomforest Classifer\n",
    "randomforest_mot1=rfc_mot1.fit(X_train_mot1, y_train_mot1)\n",
    "\n",
    "\n",
    "model_knn = KNeighborsClassifier(n_neighbors=7)\n",
    "modelknn_mot1=model_knn.fit(X_train_mot1, y_train_mot1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset = Test dataset\n",
      "Train=92398; Test=39545; Accuracy Adaboost:0.8995827538247566\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95     35408\n",
      "           1       0.53      0.02      0.04      2829\n",
      "           2       0.48      0.09      0.15      1308\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     39545\n",
      "   macro avg       0.64      0.37      0.38     39545\n",
      "weighted avg       0.86      0.90      0.86     39545\n",
      "\n",
      "Train=92398; Test=39545; Accuracy RandomForest:0.9855860412188646\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     35408\n",
      "           1       0.95      0.89      0.92      2829\n",
      "           2       0.91      0.85      0.88      1308\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     39545\n",
      "   macro avg       0.95      0.91      0.93     39545\n",
      "weighted avg       0.99      0.99      0.99     39545\n",
      "\n",
      "Train=92398; Test=39545;  Accuracy KNN:0.906713870274371\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95     35408\n",
      "           1       0.60      0.28      0.38      2829\n",
      "           2       0.37      0.10      0.15      1308\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     39545\n",
      "   macro avg       0.63      0.45      0.50     39545\n",
      "weighted avg       0.88      0.91      0.89     39545\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Predict the response for test dataset\n",
    "y_mot1_prediction_ada  = adaboost_mot1.predict(X_test_mot1)\n",
    "y_mot1_prediction_rf  = randomforest_mot1.predict(X_test_mot1 ) \n",
    "y_mot1_prediction_knn = modelknn_mot1.predict(X_test_mot1) \n",
    "\n",
    "#Accuracy with the same dataset\n",
    "print(\"Train dataset = Test dataset\")\n",
    "print(\"Train=%s; Test=%s; Accuracy Adaboost:%s\" %(len(X_train_mot1 ),len(X_test_mot1 ),metrics.accuracy_score(y_test_mot1 , y_mot1_prediction_ada )))\n",
    "print(classification_report(y_test_mot1,y_mot1_prediction_ada))\n",
    "print(\"Train=%s; Test=%s; Accuracy RandomForest:%s\" %(len(X_train_mot1 ),len(X_test_mot1 ),metrics.accuracy_score(y_test_mot1 , y_mot1_prediction_rf )))\n",
    "print(classification_report(y_test_mot1,y_mot1_prediction_rf))\n",
    "print(\"Train=%s; Test=%s;  Accuracy KNN:%s\" %(len(X_train_mot1),len(X_test_mot1),metrics.accuracy_score(y_test_mot1, y_mot1_prediction_knn)))\n",
    "print(classification_report(y_test_mot1,y_mot1_prediction_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "#               MOTIFS-2 ML\n",
    "####################################################################\n",
    "\n",
    "motif2_data1=motif2_data1.fillna(0,subset=[\"amount_sent_from_in\",\"fee1\"])\n",
    "motif2_feature=motif2_data1.withColumnRenamed(\"outuser\",\"user\")\n",
    "\n",
    "#Transform label to class index (input (?) middle (?) and output)\n",
    "motif2_feature=transform_label_to_id(motif2_feature,\"label\",\"user\")\n",
    "motif2_feature=transform_label_to_id(motif2_feature,\"labelin\",\"inuser\")\n",
    "motif2_feature=transform_label_to_id(motif2_feature,\"labelmid\",\"miduser\")\n",
    "\n",
    "motif2_feature =motif2_feature.withColumn(\"labelin\", f.col(\"labelin\").cast(\"integer\"))\n",
    "motif2_feature =motif2_feature.withColumn(\"labelmid\", f.col(\"labelmid\").cast(\"integer\"))\n",
    "\n",
    "df_motifs2=motif2_feature.randomSplit([0.7,0.3])\n",
    "\n",
    "#Split the input and the output from dataframe \n",
    "#mot2_X=df_motifs2[0].select(\"labelin\",\"labelmid\",\"address_recv_dist_to_out\",\"amount_recv_to_out\",\"fee2\",\\\n",
    "#                         \"tx_sent_from_mid\",\"address_sent_from_mid\",\"amount_sent_from_mid\",\\\n",
    "#                         \"address_recv_to_mid\",\"amount_recv_to_mid\",\"tx_sent_from_in\",\"address_sent_from_in\",\\\n",
    "#                         \"amount_sent_from_in\",\"fee1\",\"loop_mid_out\",\"loop_in_mid\",\"loop_in_out\",\\\n",
    "#                         \"direct_mid_out\",\"direct_in_mid\",\"direct_in_out\")\n",
    "\n",
    "mot2_X=df_motifs2[0].select(\"address_recv_dist_to_out\",\"amount_recv_to_out\",\"fee2\",\\\n",
    "                         \"tx_sent_from_mid\",\"address_sent_from_mid\",\"amount_sent_from_mid\",\\\n",
    "                         \"address_recv_to_mid\",\"amount_recv_to_mid\",\"tx_sent_from_in\",\"address_sent_from_in\",\\\n",
    "                         \"amount_sent_from_in\",\"fee1\",\"loop_mid_out\",\"loop_in_mid\",\"loop_in_out\",\\\n",
    "                         \"direct_mid_out\",\"direct_in_mid\",\"direct_in_out\")\n",
    "\n",
    "mot2_y=df_motifs2[0].select(\"label\")\n",
    "\n",
    "#Round amount field\n",
    "mot2_X = mot2_X.withColumn(\"amount_recv_to_out\", f.round(mot2_X[\"amount_recv_to_out\"], 6))\n",
    "mot2_X = mot2_X.withColumn(\"amount_sent_from_mid\", f.round(mot2_X[\"amount_sent_from_mid\"], 6))\n",
    "mot2_X = mot2_X.withColumn(\"amount_recv_to_mid\", f.round(mot2_X[\"amount_recv_to_mid\"], 6))\n",
    "mot2_X = mot2_X.withColumn(\"amount_sent_from_in\", f.round(mot2_X[\"amount_sent_from_in\"], 6))\n",
    "mot2_X = mot2_X.withColumn(\"fee2\", f.round(mot2_X[\"fee2\"], 6))\n",
    "mot2_X = mot2_X.withColumn(\"fee1\", f.round(mot2_X[\"fee1\"], 6))\n",
    "\n",
    "#Transform input/output dataframe in vector\n",
    "X_train_mot2= mot2_X.collect()\n",
    "y_train_mot2 = mot2_y.collect()\n",
    "\n",
    "#Reshape the output vector\n",
    "y_train_mot2=np.reshape(y_train_mot2,(len(y_train_mot2),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the input and the output from dataframe \n",
    "mot2_X=df_motifs2[1].select(\"labelin\",\"labelmid\",\"address_recv_dist_to_out\",\"amount_recv_to_out\",\"fee2\",\\\n",
    "                         \"tx_sent_from_mid\",\"address_sent_from_mid\",\"amount_sent_from_mid\",\\\n",
    "                         \"address_recv_to_mid\",\"amount_recv_to_mid\",\"tx_sent_from_in\",\"address_sent_from_in\",\\\n",
    "                         \"amount_sent_from_in\",\"fee1\",\"loop_mid_out\",\"loop_in_mid\",\"loop_in_out\",\\\n",
    "                         \"direct_mid_out\",\"direct_in_mid\",\"direct_in_out\")\n",
    "\n",
    "mot2_y=df_motifs2[1].select(\"label\")\n",
    "\n",
    "#Round amount field\n",
    "mot2_X = mot2_X.withColumn(\"amount_recv_to_out\", f.round(mot2_X[\"amount_recv_to_out\"], 6))\n",
    "mot2_X = mot2_X.withColumn(\"amount_sent_from_mid\", f.round(mot2_X[\"amount_sent_from_mid\"], 6))\n",
    "mot2_X = mot2_X.withColumn(\"amount_recv_to_mid\", f.round(mot2_X[\"amount_recv_to_mid\"], 6))\n",
    "mot2_X = mot2_X.withColumn(\"amount_sent_from_in\", f.round(mot2_X[\"amount_sent_from_in\"], 6))\n",
    "mot2_X = mot2_X.withColumn(\"fee2\", f.round(mot2_X[\"fee2\"], 6))\n",
    "mot2_X = mot2_X.withColumn(\"fee1\", f.round(mot2_X[\"fee1\"], 6))\n",
    "\n",
    "#Transform input/output dataframe in vector\n",
    "X_test_mot2= mot2_X.collect()\n",
    "y_test_mot2 = mot2_y.collect()\n",
    "\n",
    "#Reshape the output vector\n",
    "y_test_mot2=np.reshape(y_test_mot2,(len(y_test_mot2),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "####################################################################\n",
    "#               ADABOOST ML\n",
    "####################################################################\n",
    "\n",
    "# Create adaboost classifer object\n",
    "abc_mot2 = AdaBoostClassifier(n_estimators=50,learning_rate=1)\n",
    "\n",
    "# Train Adaboost Classifer\n",
    "adaboost_mot2 = abc_mot2.fit(X_train_mot2, y_train_mot2)\n",
    "\n",
    "####################################################################\n",
    "#               RANDOM FOREST ML\n",
    "####################################################################\n",
    "\n",
    "#Create random forest classifer object\n",
    "rfc_mot2= RandomForestClassifier(n_jobs=2, random_state=0)\n",
    "\n",
    "#Train Randomforest Classifer\n",
    "randomforest_mot2=rfc_mot2.fit(X_train_mot2, y_train_mot2)\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "model_nb = GaussianNB()\n",
    "model_nb_mot2=model_nb.fit(X_train_mot2, y_train_mot2)\n",
    "\n",
    "model_knn = KNeighborsClassifier(n_neighbors=7)\n",
    "modelknn_mot2=model_knn.fit(X_train_mot2, y_train_mot2)\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(13,13,13),max_iter=500)\n",
    "mlp_mot2=mlp.fit(X_train_mot2, y_train_mot2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset = Test dataset\n",
      "Train=217753; Test=93284; Accuracy Adaboost:0.9120642339522319\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95     85932\n",
      "           1       0.00      0.00      0.00      5134\n",
      "           2       0.00      0.00      0.00      2218\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     93284\n",
      "   macro avg       0.31      0.33      0.32     93284\n",
      "weighted avg       0.85      0.91      0.88     93284\n",
      "\n",
      "Train=217753; Test=93284; Accuracy RandomForest:0.9933750696796878\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     85932\n",
      "           1       0.99      0.93      0.96      5134\n",
      "           2       0.99      0.91      0.95      2218\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     93284\n",
      "   macro avg       0.99      0.95      0.97     93284\n",
      "weighted avg       0.99      0.99      0.99     93284\n",
      "\n",
      "Train=217753; Test=93284;  Accuracy KNN:0.9295913554307277\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96     85932\n",
      "           1       0.64      0.31      0.42      5134\n",
      "           2       0.40      0.11      0.17      2218\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     93284\n",
      "   macro avg       0.66      0.47      0.52     93284\n",
      "weighted avg       0.91      0.93      0.91     93284\n",
      "\n",
      "Train=217753; Test=93284;  Accuracy MLP:0.9211869130826293\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     85932\n",
      "           1       0.00      0.00      0.00      5134\n",
      "           2       0.00      0.00      0.00      2218\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     93284\n",
      "   macro avg       0.31      0.33      0.32     93284\n",
      "weighted avg       0.85      0.92      0.88     93284\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train=217753; Test=93284;  Accuracy NB:0.8947515115132284\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94     85932\n",
      "           1       0.11      0.07      0.08      5134\n",
      "           2       0.00      0.00      0.00      2218\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     93284\n",
      "   macro avg       0.34      0.35      0.34     93284\n",
      "weighted avg       0.86      0.89      0.87     93284\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Predict the response for test dataset\n",
    "y_mot2_prediction_ada  = adaboost_mot2.predict(X_test_mot2)\n",
    "y_mot2_prediction_rf  = randomforest_mot2.predict(X_test_mot2) \n",
    "y_mot2_prediction_knn = modelknn_mot2.predict(X_test_mot2) \n",
    "y_mot2_prediction_mlp = mlp_mot2.predict(X_test_mot2) \n",
    "y_mot2_prediction_nb = model_nb_mot2.predict(X_test_mot2)\n",
    "\n",
    "#Accuracy with the same dataset\n",
    "print(\"Train dataset = Test dataset\")\n",
    "print(\"Train=%s; Test=%s; Accuracy Adaboost:%s\" %(len(X_train_mot2 ),len(X_test_mot2 ),metrics.accuracy_score(y_test_mot2 , y_mot2_prediction_ada )))\n",
    "print(classification_report(y_test_mot2,y_mot2_prediction_ada))\n",
    "print(\"Train=%s; Test=%s; Accuracy RandomForest:%s\" %(len(X_train_mot2 ),len(X_test_mot2 ),metrics.accuracy_score(y_test_mot2 , y_mot2_prediction_rf )))\n",
    "print(classification_report(y_test_mot2,y_mot2_prediction_rf))\n",
    "print(\"Train=%s; Test=%s;  Accuracy KNN:%s\" %(len(X_train_mot2),len(X_test_mot2),metrics.accuracy_score(y_test_mot2, y_mot2_prediction_knn)))\n",
    "print(classification_report(y_test_mot2,y_mot2_prediction_knn))\n",
    "print(\"Train=%s; Test=%s;  Accuracy MLP:%s\" %(len(X_train_mot2),len(X_test_mot2),metrics.accuracy_score(y_test_mot2, y_mot2_prediction_mlp)))\n",
    "print(classification_report(y_test_mot2,y_mot2_prediction_mlp))\n",
    "print(\"Train=%s; Test=%s;  Accuracy NB:%s\" %(len(X_train_mot2),len(X_test_mot2),metrics.accuracy_score(y_test_mot2, y_mot2_prediction_nb)))\n",
    "print(classification_report(y_test_mot2,y_mot2_prediction_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_ada = '/home/titanium/spark_ml/nolabel/adaboost_mot2.pkl'\n",
    "filename_rfc = '/home/titanium/spark_ml/nolabel/randomforest_mot2.pkl'\n",
    "filename_knn = '/home/titanium/spark_ml/nolabel/knn_mot2.pkl'\n",
    "pickle.dump(adaboost_mot2, open(filename_ada, 'wb'))\n",
    "pickle.dump(randomforest_mot2, open(filename_rfc, 'wb'))\n",
    "pickle.dump(modelknn_mot2, open(filename_knn, 'wb'))\n",
    "\n",
    "\n",
    "filename_ada = '/home/titanium/spark_ml/nolabel/adaboost_mot1.pkl'\n",
    "filename_rfc = '/home/titanium/spark_ml/nolabel/randomforest_mot1.pkl'\n",
    "filename_knn = '/home/titanium/spark_ml/nolabel/knn_mot1.pkl'\n",
    "pickle.dump(adaboost_mot1, open(filename_ada, 'wb'))\n",
    "pickle.dump(randomforest_mot1, open(filename_rfc, 'wb'))\n",
    "pickle.dump(modelknn_mot1, open(filename_knn, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "#              SAVE MODEL\n",
    "#############################################################################\n",
    "\n",
    "filename_ada = '/home/titanium/spark_ml/address/adaboost_add.pkl'\n",
    "filename_rfc = '/home/titanium/spark_ml/address/randomforest_add.pkl'\n",
    "filename_knn = '/home/titanium/spark_ml/address/knn_add.pkl'\n",
    "pickle.dump(adaboost_add, open(filename_ada, 'wb'))\n",
    "pickle.dump(randomforest_add, open(filename_rfc, 'wb'))\n",
    "pickle.dump(modelknn_add, open(filename_knn, 'wb'))\n",
    "\n",
    "filename_ada = '/home/titanium/spark_ml/entity/adaboost_ent.pkl'\n",
    "filename_rfc = '/home/titanium/spark_ml/entity/randomforest_ent.pkl'\n",
    "filename_knn = '/home/titanium/spark_ml/entity/knn_ent.pkl'\n",
    "pickle.dump(adaboost_ent, open(filename_ada, 'wb'))\n",
    "pickle.dump(randomforest_ent, open(filename_rfc, 'wb'))\n",
    "pickle.dump(modelknn_ent, open(filename_knn, 'wb'))\n",
    "\n",
    "\n",
    "filename_ada = '/home/titanium/spark_ml/motifs1/adaboost_mot1.pkl'\n",
    "filename_rfc = '/home/titanium/spark_ml/motifs1/randomforest_mot1.pkl'\n",
    "filename_knn = '/home/titanium/spark_ml/motifs1/knn_mot1.pkl'\n",
    "pickle.dump(adaboost_mot1, open(filename_ada, 'wb'))\n",
    "pickle.dump(randomforest_mot1, open(filename_rfc, 'wb'))\n",
    "pickle.dump(modelknn_mot1, open(filename_knn, 'wb'))\n",
    "\n",
    "filename_ada = '/home/titanium/spark_ml/motifs2/adaboost_mot2.pkl'\n",
    "filename_rfc = '/home/titanium/spark_ml/motifs2/randomforest_mot2.pkl'\n",
    "filename_knn = '/home/titanium/spark_ml/motifs2/knn_mot2.pkl'\n",
    "pickle.dump(adaboost_mot2, open(filename_ada, 'wb'))\n",
    "pickle.dump(randomforest_mot2, open(filename_rfc, 'wb'))\n",
    "pickle.dump(modelknn_mot2, open(filename_knn, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "address_feature2=df_address[1].select(\"user\").collect()\n",
    "motif1_feature2=df_motifs1[1].select(\"user\").collect()\n",
    "motif2_feature2=df_motifs2[1].select(\"user\").collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dataframe with the result of previuos classifier\n",
    "\n",
    "#############################################################################\n",
    "#               ADDRESS DATAFRAME\n",
    "#############################################################################\n",
    "\n",
    "#Set ENTITY dataframe for the final classifier\n",
    "entity_data1 = entity_data1.filter(f.col(\"user\")!=\"Unknow\")\n",
    "entity_data1 = entity_data1.fillna(0)\n",
    "\n",
    "entity_feature=entity_data1\n",
    "\n",
    "#############################################################################\n",
    "#               ADDRESS DATAFRAME\n",
    "#############################################################################\n",
    "#Link the ADABOOST prediction with the input tag/label\n",
    "DF=link_outclass_intag(address_feature2,y_add_prediction_ada)\n",
    "#Join the prediction about the same input tag/label\n",
    "address_pred_feature_ada = join_dataframe_intag(DF,\"add\")\n",
    "\n",
    "#Link the RANDOMFOREST prediction with the input tag/label\n",
    "DF=link_outclass_intag(address_feature2,y_add_prediction_rf)\n",
    "#Join the prediction about the same input tag/label\n",
    "address_pred_feature_rf = join_dataframe_intag(DF,\"add\")\n",
    "\n",
    "#Link the RANDOMFOREST prediction with the input tag/label\n",
    "DF=link_outclass_intag(address_feature2,y_add_prediction_knn)\n",
    "#Join the prediction about the same input tag/label\n",
    "address_pred_feature_knn = join_dataframe_intag(DF,\"add\")\n",
    "#############################################################################\n",
    "#               MOTIFS-1 DATAFRAME\n",
    "#############################################################################\n",
    "\n",
    "#Link the ADABOOST prediction with the input tag/label\n",
    "DF=link_outclass_intag(motif1_feature2,y_mot1_prediction_ada)\n",
    "#Join the prediction about the same input tag/label\n",
    "motif1_pred_feature_ada = join_dataframe_intag(DF,\"mot1\")\n",
    "\n",
    "#Link the RANDOMFOREST prediction with the input tag/label\n",
    "DF=link_outclass_intag(motif1_feature2,y_mot1_prediction_rf)\n",
    "#Join the prediction about the same input tag/label\n",
    "motif1_pred_feature_rf = join_dataframe_intag(DF,\"mot1\")\n",
    "\n",
    "\n",
    "#Link the RANDOMFOREST prediction with the input tag/label\n",
    "DF=link_outclass_intag(motif1_feature2,y_mot1_prediction_knn)\n",
    "#Join the prediction about the same input tag/label\n",
    "motif1_pred_feature_knn = join_dataframe_intag(DF,\"mot1\")\n",
    "#############################################################################\n",
    "#               MOTIFS-2 DATAFRAME\n",
    "#############################################################################\n",
    "\n",
    "#Link the ADABOOST prediction with the input tag/label\n",
    "DF=link_outclass_intag(motif2_feature2,y_mot2_prediction_ada)\n",
    "#Join the prediction about the same input tag/label\n",
    "motif2_pred_feature_ada = join_dataframe_intag(DF,\"mot2\")\n",
    "\n",
    "#Link the RANDOMFOREST prediction with the input tag/label\n",
    "DF=link_outclass_intag(motif2_feature2,y_mot2_prediction_rf)\n",
    "#Join the prediction about the same input tag/label\n",
    "motif2_pred_feature_rf = join_dataframe_intag(DF,\"mot2\")\n",
    "\n",
    "#Link the RANDOMFOREST prediction with the input tag/label\n",
    "DF=link_outclass_intag(motif2_feature2,y_mot2_prediction_knn)\n",
    "#Join the prediction about the same input tag/label\n",
    "motif2_pred_feature_knn = join_dataframe_intag(DF,\"mot2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join all the dataframe information\n",
    "\n",
    "#############################################################################\n",
    "#               ADABOOST DATAFRAME CREATION\n",
    "#############################################################################\n",
    "df_final_ada = entity_feature.join(address_pred_feature_ada,['user'])\n",
    "df_final_ada = df_final_ada.join(motif1_pred_feature_ada,['user'])\n",
    "df_final_ada  = df_final_ada.join(motif2_pred_feature_ada,['user'])\n",
    "df_final_ada  = transform_label_to_id(df_final_ada ,\"label\",\"user\")\n",
    "\n",
    "#############################################################################\n",
    "#               RANDOM FOREST DATAFRAME CREATION\n",
    "#############################################################################\n",
    "df_final_rf = entity_feature.join(address_pred_feature_rf,['user'])\n",
    "df_final_rf = df_final_rf.join(motif1_pred_feature_rf,['user'])\n",
    "df_final_rf = df_final_rf.join(motif2_pred_feature_rf,['user'])\n",
    "df_final_rf = transform_label_to_id(df_final_rf,\"label\",\"user\")\n",
    "\n",
    "#############################################################################\n",
    "#               RANDOM FOREST DATAFRAME CREATION\n",
    "#############################################################################\n",
    "df_final_knn = entity_feature.join(address_pred_feature_knn,['user'])\n",
    "df_final_knn = df_final_knn.join(motif1_pred_feature_knn,['user'])\n",
    "df_final_knn = df_final_knn.join(motif2_pred_feature_knn,['user'])\n",
    "df_final_knn = transform_label_to_id(df_final_knn,\"label\",\"user\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "#               ADABOOST DATAFRAME CREATION\n",
    "#############################################################################\n",
    "\n",
    "df_final_ada_split=df_final_ada.randomSplit([0.7,0.3])\n",
    "\n",
    "#Split the input from the output data\n",
    "ada_final_X=df_final_ada_split[0].select(\"balance_recv\",\"balancein\",\"balance\",\"count_recv\",\"count_sent\",\\\n",
    "                        \"add_cnt0\",\"add_cnt1\",\"add_cnt2\",\"add_cnt3\",\\\n",
    "                        \"mot1_cnt0\",\"mot1_cnt1\",\"mot1_cnt2\",\"mot1_cnt3\",\\\n",
    "                        \"mot2_cnt0\",\"mot2_cnt1\",\"mot2_cnt2\",\"mot2_cnt3\")\n",
    "\n",
    "ada_final_y=df_final_ada_split[0].select(\"label\")\n",
    "\n",
    "#Round amount field\n",
    "ada_final_X = ada_final_X.withColumn(\"balance_recv\", f.round(ada_final_X[\"balance_recv\"], 6))\n",
    "ada_final_X = ada_final_X.withColumn(\"balancein\", f.round(ada_final_X[\"balancein\"], 6))\n",
    "ada_final_X = ada_final_X.withColumn(\"balance\", f.round(ada_final_X[\"balance\"], 6))\n",
    "\n",
    "#Transform input/output dataframe in vector\n",
    "ada_final_X_train = ada_final_X.fillna(0).collect()\n",
    "ada_final_y_train = ada_final_y.collect()\n",
    "\n",
    "#Reshape the output vector\n",
    "ada_final_y_train=np.reshape(ada_final_y_train,(len(ada_final_y_train),))\n",
    "\n",
    "#Split the input from the output data\n",
    "ada_final_X=df_final_ada_split[1].select(\"balance_recv\",\"balancein\",\"balance\",\"count_recv\",\"count_sent\",\\\n",
    "                        \"add_cnt0\",\"add_cnt1\",\"add_cnt2\",\"add_cnt3\",\\\n",
    "                        \"mot1_cnt0\",\"mot1_cnt1\",\"mot1_cnt2\",\"mot1_cnt3\",\\\n",
    "                        \"mot2_cnt0\",\"mot2_cnt1\",\"mot2_cnt2\",\"mot2_cnt3\")\n",
    "\n",
    "ada_final_y=df_final_ada_split[1].select(\"label\")\n",
    "\n",
    "#Round amount field\n",
    "ada_final_X = ada_final_X.withColumn(\"balance_recv\", f.round(ada_final_X[\"balance_recv\"], 6))\n",
    "ada_final_X = ada_final_X.withColumn(\"balancein\", f.round(ada_final_X[\"balancein\"], 6))\n",
    "ada_final_X = ada_final_X.withColumn(\"balance\", f.round(ada_final_X[\"balance\"], 6))\n",
    "\n",
    "#Transform input/output dataframe in vector\n",
    "ada_final_X_test = ada_final_X.fillna(0).collect()\n",
    "ada_final_y_test = ada_final_y.collect()\n",
    "\n",
    "#Reshape the output vector\n",
    "ada_final_y_test=np.reshape(ada_final_y_test,(len(ada_final_y_test),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "#               RANDOMFOREST DATAFRAME CREATION\n",
    "#############################################################################\n",
    "df_final_rf_split=df_final_rf.randomSplit([0.7,0.3])\n",
    "\n",
    "rf_final_X=df_final_rf_split[0].select(\"balance_recv\",\"balancein\",\"balance\",\"count_recv\",\"count_sent\",\\\n",
    "                        \"add_cnt0\",\"add_cnt1\",\"add_cnt2\",\"add_cnt3\",\\\n",
    "                        \"mot1_cnt0\",\"mot1_cnt1\",\"mot1_cnt2\",\"mot1_cnt3\",\\\n",
    "                        \"mot2_cnt0\",\"mot2_cnt1\",\"mot2_cnt2\",\"mot2_cnt3\")\n",
    "\n",
    "rf_final_y=df_final_rf_split[0].select(\"label\")\n",
    "\n",
    "#Round amount field\n",
    "rf_final_X = rf_final_X.withColumn(\"balance_recv\", f.round(rf_final_X[\"balance_recv\"], 6))\n",
    "rf_final_X = rf_final_X.withColumn(\"balancein\", f.round(rf_final_X[\"balancein\"], 6))\n",
    "rf_final_X = rf_final_X.withColumn(\"balance\", f.round(rf_final_X[\"balance\"], 6))\n",
    "\n",
    "#Transform input/output dataframe in vector\n",
    "rf_final_X_train = rf_final_X.fillna(0).collect()\n",
    "rf_final_y_train = rf_final_y.collect()\n",
    "\n",
    "#Reshape the output vector\n",
    "rf_final_y_train=np.reshape(rf_final_y_train,(len(rf_final_y_train),))\n",
    "\n",
    "rf_final_X=df_final_rf_split[1].select(\"balance_recv\",\"balancein\",\"balance\",\"count_recv\",\"count_sent\",\\\n",
    "                        \"add_cnt0\",\"add_cnt1\",\"add_cnt2\",\"add_cnt3\",\\\n",
    "                        \"mot1_cnt0\",\"mot1_cnt1\",\"mot1_cnt2\",\"mot1_cnt3\",\\\n",
    "                        \"mot2_cnt0\",\"mot2_cnt1\",\"mot2_cnt2\",\"mot2_cnt3\")\n",
    "\n",
    "rf_final_y=df_final_rf_split[1].select(\"label\")\n",
    "\n",
    "#Round amount field\n",
    "rf_final_X = rf_final_X.withColumn(\"balance_recv\", f.round(rf_final_X[\"balance_recv\"], 6))\n",
    "rf_final_X = rf_final_X.withColumn(\"balancein\", f.round(rf_final_X[\"balancein\"], 6))\n",
    "rf_final_X = rf_final_X.withColumn(\"balance\", f.round(rf_final_X[\"balance\"], 6))\n",
    "\n",
    "#Transform input/output dataframe in vector\n",
    "rf_final_X_test = rf_final_X.fillna(0).collect()\n",
    "rf_final_y_test = rf_final_y.collect()\n",
    "\n",
    "#Reshape the output vector\n",
    "rf_final_y_test=np.reshape(rf_final_y_test,(len(rf_final_y_test),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "#               RANDOMFOREST DATAFRAME CREATION\n",
    "#############################################################################\n",
    "df_final_knn_split=df_final_knn.randomSplit([0.7,0.3])\n",
    "\n",
    "knn_final_X=df_final_knn_split[0].select(\"balance_recv\",\"balancein\",\"balance\",\"count_recv\",\"count_sent\",\\\n",
    "                        \"add_cnt0\",\"add_cnt1\",\"add_cnt2\",\"add_cnt3\",\\\n",
    "                        \"mot1_cnt0\",\"mot1_cnt1\",\"mot1_cnt2\",\"mot1_cnt3\",\\\n",
    "                        \"mot2_cnt0\",\"mot2_cnt1\",\"mot2_cnt2\",\"mot2_cnt3\")\n",
    "\n",
    "knn_final_y=df_final_knn_split[0].select(\"label\")\n",
    "\n",
    "#Round amount field\n",
    "knn_final_X = knn_final_X.withColumn(\"balance_recv\", f.round(knn_final_X[\"balance_recv\"], 6))\n",
    "knn_final_X = knn_final_X.withColumn(\"balancein\", f.round(knn_final_X[\"balancein\"], 6))\n",
    "knn_final_X = knn_final_X.withColumn(\"balance\", f.round(knn_final_X[\"balance\"], 6))\n",
    "\n",
    "#Transform input/output dataframe in vector\n",
    "knn_final_X_train = knn_final_X.fillna(0).collect()\n",
    "knn_final_y_train = knn_final_y.collect()\n",
    "\n",
    "#Reshape the output vector\n",
    "knn_final_y_train=np.reshape(knn_final_y_train,(len(knn_final_y_train),))\n",
    "\n",
    "knn_final_X=df_final_knn_split[1].select(\"balance_recv\",\"balancein\",\"balance\",\"count_recv\",\"count_sent\",\\\n",
    "                        \"add_cnt0\",\"add_cnt1\",\"add_cnt2\",\"add_cnt3\",\\\n",
    "                        \"mot1_cnt0\",\"mot1_cnt1\",\"mot1_cnt2\",\"mot1_cnt3\",\\\n",
    "                        \"mot2_cnt0\",\"mot2_cnt1\",\"mot2_cnt2\",\"mot2_cnt3\")\n",
    "\n",
    "knn_final_y=df_final_knn_split[1].select(\"label\")\n",
    "\n",
    "#Round amount field\n",
    "knn_final_X = knn_final_X.withColumn(\"balance_recv\", f.round(knn_final_X[\"balance_recv\"], 6))\n",
    "knn_final_X = knn_final_X.withColumn(\"balancein\", f.round(knn_final_X[\"balancein\"], 6))\n",
    "knn_final_X = knn_final_X.withColumn(\"balance\", f.round(knn_final_X[\"balance\"], 6))\n",
    "\n",
    "#Transform input/output dataframe in vector\n",
    "knn_final_X_test = knn_final_X.fillna(0).collect()\n",
    "knn_final_y_test = knn_final_y.collect()\n",
    "\n",
    "#Reshape the output vector\n",
    "knn_final_y_test=np.reshape(knn_final_y_test,(len(knn_final_y_test),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#############################################################################\n",
    "#               ADABOOST FINAL CLASSIFICATOR\n",
    "#############################################################################\n",
    "\n",
    "# Create adaboost classifer object\n",
    "abc_final = AdaBoostClassifier(n_estimators=50,learning_rate=1)\n",
    "\n",
    "# Train Adaboost Classifer\n",
    "adaboost_final = abc_final.fit(ada_final_X_train, ada_final_y_train)\n",
    "\n",
    "#############################################################################\n",
    "#               RANDOMFOREST FINAL CLASSIFICATOR\n",
    "#############################################################################\n",
    "\n",
    "#Create random forest classifer object\n",
    "rfc_final= RandomForestClassifier(n_jobs=2, random_state=0)  \n",
    "#Train Randomforest Classifer\n",
    "randomforest_final=rfc_final.fit(rf_final_X_train, rf_final_y_train)\n",
    "\n",
    "#############################################################################\n",
    "#               RANDOMFOREST FINAL CLASSIFICATOR\n",
    "#############################################################################\n",
    "\n",
    "#Create random forest classifer object\n",
    "rfc_final_to_knn= RandomForestClassifier(n_jobs=2, random_state=0)  \n",
    "#Train Randomforest Classifer\n",
    "randomforest_final_to_knn=rfc_final_to_knn.fit(knn_final_X_train, knn_final_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset = Test dataset\n",
      "Train=840; Test=348; Accuracy Adaboost:0.985632183908046\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       292\n",
      "           1       1.00      0.92      0.96        26\n",
      "           2       1.00      0.90      0.95        30\n",
      "\n",
      "   micro avg       0.99      0.99      0.99       348\n",
      "   macro avg       0.99      0.94      0.97       348\n",
      "weighted avg       0.99      0.99      0.99       348\n",
      "\n",
      "Train=834; Test=354; Accuracy RandomForest:1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       303\n",
      "           1       1.00      1.00      1.00        26\n",
      "           2       1.00      1.00      1.00        25\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       354\n",
      "   macro avg       1.00      1.00      1.00       354\n",
      "weighted avg       1.00      1.00      1.00       354\n",
      "\n",
      "Train=840; Test=348; Accuracy RandomForest from KNN:1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       297\n",
      "           1       1.00      1.00      1.00        25\n",
      "           2       1.00      1.00      1.00        26\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       348\n",
      "   macro avg       1.00      1.00      1.00       348\n",
      "weighted avg       1.00      1.00      1.00       348\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Predict the response for test dataset\n",
    "y_prediction_ada = adaboost_final.predict(ada_final_X_test)\n",
    "y_prediction_rf= randomforest_final.predict(rf_final_X_test) \n",
    "y_prediction_knn= randomforest_final_to_knn.predict(knn_final_X_test) \n",
    "\n",
    "#Accuracy with the same dataset\n",
    "print(\"Train dataset = Test dataset\")\n",
    "print(\"Train=%s; Test=%s; Accuracy Adaboost:%s\" %(len(ada_final_X_train ),len(ada_final_X_test ),metrics.accuracy_score(ada_final_y_test , y_prediction_ada )))\n",
    "print(classification_report(ada_final_y_test,y_prediction_ada))\n",
    "print(\"Train=%s; Test=%s; Accuracy RandomForest:%s\" %(len(rf_final_X_train ),len(rf_final_X_test ),metrics.accuracy_score(rf_final_y_test , y_prediction_rf )))\n",
    "print(classification_report(rf_final_y_test,y_prediction_rf))\n",
    "print(\"Train=%s; Test=%s; Accuracy RandomForest from KNN:%s\" %(len(knn_final_X_train ),len(knn_final_X_test),metrics.accuracy_score(knn_final_y_test , y_prediction_knn )))\n",
    "print(classification_report(knn_final_y_test,y_prediction_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "#              SAVE MODEL\n",
    "#############################################################################\n",
    "filename_ada = '/home/titanium/spark_ml/final/adaboost_final.pkl'\n",
    "filename_rfc = '/home/titanium/spark_ml/final/randomforest_final.pkl'\n",
    "filename_knn = '/home/titanium/spark_ml/final/randomforest_final_toknn.pkl'\n",
    "pickle.dump(adaboost_final, open(filename_ada, 'wb'))\n",
    "pickle.dump(randomforest_final, open(filename_rfc, 'wb'))\n",
    "pickle.dump(randomforest_final_to_knn, open(filename_knn, 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_directory=\"dataframe_join/join123\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "#              LOAD MODEL\n",
    "#############################################################################\n",
    "filename_ada = '/home/titanium/spark_ml/adaboost_add.pkl'\n",
    "filename_rfc = '/home/titanium/spark_ml/randomforest_add.pkl'\n",
    "loaded_model_ada_add = pickle.load(open(filename_ada, 'rb'))\n",
    "loaded_model_rfc_add = pickle.load(open(filename_rfc, 'rb'))\n",
    "\n",
    "filename_ada = '/home/titanium/spark_ml/adaboost_mot1.pkl'\n",
    "filename_rfc = '/home/titanium/spark_ml/randomforest_mot1.pkl'\n",
    "loaded_model_ada_mot1 = pickle.load(open(filename_ada, 'rb'))\n",
    "loaded_model_rfc_mot1 = pickle.load(open(filename_rfc, 'rb'))\n",
    "\n",
    "filename_ada = '/home/titanium/spark_ml/adaboost_mot2.pkl'\n",
    "filename_rfc = '/home/titanium/spark_ml/randomforest_mot2.pkl'\n",
    "loaded_model_ada_mot2 = pickle.load(open(filename_ada, 'rb'))\n",
    "loaded_model_rfc_mot2 = pickle.load(open(filename_rfc, 'rb'))\n",
    "\n",
    "filename_ada = '/home/titanium/spark_ml/adaboost_final.pkl'\n",
    "filename_rfc = '/home/titanium/spark_ml/randomforest_final.pkl'\n",
    "loaded_model_ada_final = pickle.load(open(filename_ada, 'rb'))\n",
    "loaded_model_rfc_final = pickle.load(open(filename_rfc, 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gambling = sqlContext.read.format('com.databricks.spark.csv')\\\n",
    ".option('header','true')\\\n",
    ".option(\"inferSchema\", \"true\")\\\n",
    ".load(path+\"walletexp_data/gambling*\")\n",
    "\n",
    "df_exchange = sqlContext.read.format('com.databricks.spark.csv')\\\n",
    ".option('header','true')\\\n",
    ".option(\"inferSchema\", \"true\")\\\n",
    ".load(path+\"walletexp_data/exchange*\")\n",
    "\n",
    "df_exchange =df_exchange.withColumn(\"xxx\",f.lit(1))\n",
    "df_gambling =df_gambling.withColumn(\"xxx\",f.lit(2))\n",
    "df_label = df_exchange.union(df_gambling).groupby(\"label\").agg(f.first(\"xxx\").alias(\"class\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "#               IMPORT DATAFRAMES\n",
    "#########################################################################\n",
    "\n",
    "entity_data2= sqlContext.read.format('com.databricks.spark.csv')\\\n",
    ".option('header','true')\\\n",
    ".option(\"inferSchema\", \"true\")\\\n",
    ".load(path+path_directory+\"/entity/\")\n",
    "\n",
    "address_data2 = sqlContext.read.format('com.databricks.spark.csv')\\\n",
    ".option('header','true')\\\n",
    ".option(\"inferSchema\", \"true\")\\\n",
    ".load(path+path_directory+\"/address/\")\n",
    "\n",
    "#motif1_data2 = sqlContext.read.format('com.databricks.spark.csv')\\\n",
    "#.option('header','true')\\\n",
    "#.option(\"inferSchema\", \"true\")\\\n",
    "#.load(path+path_directory+\"/motif1/\")\n",
    "\n",
    "#motif2_data2 = sqlContext.read.format('com.databricks.spark.csv')\\\n",
    "#.option('header','true')\\\n",
    "#.option(\"inferSchema\", \"true\")\\\n",
    "#.load(path+path_directory+\"/motif2/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "address_data2=address_data2.groupby(\"address\").agg(f.first(\"label\").alias(\"label\"),f.first(\"user\").alias(\"user\"),\\\n",
    "                                     f.sum(\"count_rec\").alias(\"count_rec\"),f.sum(\"totamount_rec\").alias(\"totamount_rec\"),\\\n",
    "                                    f.sum(\"count_sent\").alias(\"count_sent\"),f.sum(\"totamount_sent\").alias(\"totamount_sent\"),\\\n",
    "                                    f.sum(\"balance\").alias(\"balance\"),f.min(\"unique\").alias(\"unique\"),f.sum(\"sibling\").alias(\"sibling\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train=0; Test=425689;  Accuracy Adaboost:0.0008879722050605019\n",
      "Train=0; Test=425689;  Accuracy RandomForest:0.0005356022824174456\n"
     ]
    }
   ],
   "source": [
    "####################################################################\n",
    "#               ADDRESS ML\n",
    "####################################################################\n",
    "\n",
    "#address_data2 = address_data2.filter(f.col(\"user\")!=\"Unknow\")\n",
    "\n",
    "#Transform label to class index \n",
    "#address_feature_test=transform_label_to_id(address_data2,\"label\",\"user\")\n",
    "\n",
    "#Split the input and the output from dataframe \n",
    "address_feature_test=address_data2\n",
    "add_X_test=address_feature_test.select(\"count_rec\",\"totamount_rec\",\"count_sent\",\"totamount_sent\",\"balance\",\"unique\",\"sibling\")\n",
    "add_y_test=address_feature_test.select(\"label\")\n",
    "add_y_test = add_y_test.withColumn(\"label\", f.col(\"label\").cast(\"string\"))\n",
    "add_y_test_class = address_feature_test.select(\"user\")\n",
    "\n",
    "#Round amount field\n",
    "add_X_test = add_X_test.withColumn(\"totamount_rec\", f.round(add_X_test[\"totamount_rec\"], 6))\n",
    "add_X_test = add_X_test.withColumn(\"totamount_sent\", f.round(add_X_test[\"totamount_sent\"], 6))\n",
    "add_X_test = add_X_test.withColumn(\"balance\", f.round(add_X_test[\"balance\"], 6))\n",
    "\n",
    "#Transform input/output dataframe in vector\n",
    "X_test_add = add_X_test.collect()\n",
    "y_test_add = add_y_test.collect()\n",
    "\n",
    "#Reshape the output vector\n",
    "y_test_add=np.reshape(y_test_add,(len(y_test_add),))\n",
    "\n",
    "\n",
    "####################################################################\n",
    "#               EVALUATION CLASSIFIER\n",
    "####################################################################\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_add_prediction_ada_test = loaded_model_ada_add.predict(X_test_add)\n",
    "y_add_prediction_rf_test = loaded_model_rfc_add.predict(X_test_add) \n",
    "\n",
    "#Accuracy with the same dataset\n",
    "print(\"Train=%s; Test=%s;  Accuracy Adaboost:%s\" %(0,len(X_test_add),metrics.accuracy_score( y_test_add,y_add_prediction_ada_test)))\n",
    "print(\"Train=%s; Test=%s;  Accuracy RandomForest:%s\" %(0,len(X_test_add),metrics.accuracy_score( y_test_add,y_add_prediction_rf_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "motif1_feature_test=motif1_data2.withColumnRenamed(\"outuser\",\"user\")\n",
    "\n",
    "motif1_feature_split = motif1_feature_test.randomSplit([.25,.25,.25,.25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "#               MOTIFS-1 ML\n",
    "####################################################################\n",
    "\n",
    "#Transform label to class index (input (?) and output)\n",
    "#motif1_feature_test=transform_label_to_id(motif1_feature_test,\"label\",\"user\")\n",
    "#motif1_feature_test=transform_label_to_id(motif1_feature_test,\"labelin\",\"inuser\")\n",
    "for i in range(0,4):\n",
    "    #Split the input and the output from dataframe \n",
    "    mot1_X_test0=motif1_feature_split[i].select(\"labelin\",\"address_recv_dist\",\"amount_recv\",\"tx_sent\",\"address_sent_dist\",\"amount_sent\",\"tx_recv_tot\",\"fees\",\"loop_in_out\",\"direct_in_out\")\n",
    "    mot1_y_test0=motif1_feature_split[i].select(\"label\")\n",
    "    mot1_y_test0 = mot1_y_test0.withColumn(\"label\", f.col(\"label\").cast(\"string\"))\n",
    "    mot1_y_class0=motif1_feature_split[i].select(\"user\").collect()\n",
    "\n",
    "    #Round amount field\n",
    "    mot1_X_test0 = mot1_X_test0.withColumn(\"amount_recv\", f.round(mot1_X_test0[\"amount_recv\"], 6))\n",
    "    mot1_X_test0 = mot1_X_test0.withColumn(\"amount_sent\", f.round(mot1_X_test0[\"amount_sent\"], 6))\n",
    "    mot1_X_test0 = mot1_X_test0.withColumn(\"fees\", f.round(mot1_X_test0[\"fees\"], 6))\n",
    "    #Transform input/output dataframe in vector\n",
    "    X_test_mot10 = mot1_X_test0.collect()\n",
    "    y_test_mot10 = mot1_y_test0.collect()\n",
    "    \n",
    "    if(i==0):\n",
    "        X_test_mot1=X_test_mot10\n",
    "        y_test_mot1=y_test_mot10\n",
    "        mot1_y_class=mot1_y_class0\n",
    "    else:\n",
    "        X_test_mot1=X_test_mot1+X_test_mot10\n",
    "        y_test_mot1=y_test_mot1+y_test_mot10\n",
    "        mot1_y_class=mot1_y_class+mot1_y_class0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train=0; Test=2148239; Accuracy Adaboost:0.046788090151980294\n",
      "Train=0; Test=2148239; Accuracy RandomForest:0.017907690904038143\n"
     ]
    }
   ],
   "source": [
    "####################################################################\n",
    "#               EVALUATION CLASSIFIER\n",
    "####################################################################\n",
    "#Reshape the output vector\n",
    "y_test_mot1=np.reshape(y_test_mot1,(len(y_test_mot1),))\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_mot1_prediction_ada_test  = loaded_model_ada_mot1.predict(X_test_mot1)\n",
    "y_mot1_prediction_rf_test  = loaded_model_rfc_mot1.predict(X_test_mot1 ) \n",
    "\n",
    "#Accuracy with the same dataset\n",
    "print(\"Train=%s; Test=%s; Accuracy Adaboost:%s\" %(0,len(X_test_mot1 ),metrics.accuracy_score(y_test_mot1 , y_mot1_prediction_ada_test )))\n",
    "print(\"Train=%s; Test=%s; Accuracy RandomForest:%s\" %(0,len(X_test_mot1 ),metrics.accuracy_score(y_test_mot1 , y_mot1_prediction_rf_test )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "motif2_data2=motif2_data2.fillna(0,subset=[\"amount_sent_from_in\",\"fee1\"])\n",
    "motif2_feature_test=motif2_data2.withColumnRenamed(\"outuser\",\"user\")\n",
    "\n",
    "motif2_feature_split = motif2_feature_test.randomSplit([.1,.1,.1,.1,.1,.1,.1,.1,.1,.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "#               MOTIFS-2 ML\n",
    "####################################################################\n",
    "\n",
    "\n",
    "#Transform label to class index (input (?) middle (?) and output)\n",
    "#motif2_feature_test=transform_label_to_id(motif2_feature_test,\"label\",\"user\")\n",
    "#motif2_feature_test=transform_label_to_id(motif2_feature_test,\"labelin\",\"inuser\")\n",
    "#motif2_feature_test=transform_label_to_id(motif2_feature_test,\"labelmid\",\"miduser\")\n",
    "for i in range(0,10):\n",
    "    #Split the input and the output from dataframe \n",
    "    mot2_X_test0=motif2_feature_split[i].select(\"labelin\",\"labelmid\",\"address_recv_dist_to_out\",\"amount_recv_to_out\",\"fee2\",\\\n",
    "                             \"tx_sent_from_mid\",\"address_sent_from_mid\",\"amount_sent_from_mid\",\\\n",
    "                             \"address_recv_to_mid\",\"amount_recv_to_mid\",\"tx_sent_from_in\",\"address_sent_from_in\",\\\n",
    "                             \"amount_sent_from_in\",\"fee1\",\"loop_mid_out\",\"loop_in_mid\",\"loop_in_out\",\\\n",
    "                             \"direct_mid_out\",\"direct_in_mid\",\"direct_in_out\")\n",
    "\n",
    "    mot2_y_test0=motif2_feature_split[i].select(\"label\")\n",
    "    mot2_y_test0 =mot2_y_test0.withColumn(\"label\", f.col(\"label\").cast(\"string\"))\n",
    "    mot2_y_test0_class=motif2_feature_split[i].select(\"user\").collect()\n",
    "\n",
    "    #Round amount field\n",
    "    mot2_X_test0 = mot2_X_test0.withColumn(\"amount_recv_to_out\", f.round(mot2_X_test0[\"amount_recv_to_out\"], 6))\n",
    "    mot2_X_test0 = mot2_X_test0.withColumn(\"amount_sent_from_mid\", f.round(mot2_X_test0[\"amount_sent_from_mid\"], 6))\n",
    "    mot2_X_test0 = mot2_X_test0.withColumn(\"amount_recv_to_mid\", f.round(mot2_X_test0[\"amount_recv_to_mid\"], 6))\n",
    "    mot2_X_test0 = mot2_X_test0.withColumn(\"amount_sent_from_in\", f.round(mot2_X_test0[\"amount_sent_from_in\"], 6))\n",
    "    mot2_X_test0 = mot2_X_test0.withColumn(\"fee2\", f.round(mot2_X_test0[\"fee2\"], 6))\n",
    "    mot2_X_test0 = mot2_X_test0.withColumn(\"fee1\", f.round(mot2_X_test0[\"fee1\"], 6))\n",
    "    \n",
    "    mot2_X_test0_list = mot2_X_test0.collect()\n",
    "    mot2_y_test0_list = mot2_y_test0.collect()\n",
    "        \n",
    "    if(i==0):\n",
    "        X_test_mot2=mot2_X_test0_list\n",
    "        y_test_mot2=mot2_y_test0_list\n",
    "        mot2_y_test_class=mot2_y_test0_class\n",
    "    else:\n",
    "        X_test_mot2=X_test_mot2+mot2_X_test0_list\n",
    "        y_test_mot2=y_test_mot2+mot2_y_test0_list\n",
    "        mot2_y_test_class=mot2_y_test_class+mot2_y_test0_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train=0; Test=2809380; Accuracy Adaboost:0.0006261167944528686\n",
      "Train=0; Test=2809380; Accuracy RandomForest:0.4248165075568275\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Reshape the output vector\n",
    "y_test_mot2=np.reshape(y_test_mot2,(len(y_test_mot2),))\n",
    "\n",
    "####################################################################\n",
    "#               EVALUATION CLASSIFIER\n",
    "####################################################################\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_mot2_prediction_ada_test  = loaded_model_ada_mot2.predict(X_test_mot2)\n",
    "y_mot2_prediction_rf_test  = loaded_model_rfc_mot2.predict(X_test_mot2) \n",
    "\n",
    "#Accuracy with the same dataset\n",
    "print(\"Train=%s; Test=%s; Accuracy Adaboost:%s\" %(0,len(X_test_mot2 ),metrics.accuracy_score(y_test_mot2 , y_mot2_prediction_ada_test )))\n",
    "print(\"Train=%s; Test=%s; Accuracy RandomForest:%s\" %(0,len(X_test_mot2 ),metrics.accuracy_score(y_test_mot2 , y_mot2_prediction_rf_test )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_y_test_class=add_y_test_class.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dataframe with the result of previuos classifier\n",
    "\n",
    "#############################################################################\n",
    "#               ENTITY DATAFRAME\n",
    "#############################################################################\n",
    "\n",
    "#Set ENTITY dataframe for the final classifier\n",
    "#entity_data2 = entity_data2.filter(f.col(\"user\")!=\"Unknow\")\n",
    "#entity_data2 = entity_data2.fillna(0,subset=['count_sent'])\n",
    "#entity_data2 = entity_data2.fillna(0,subset=['count_recv'])\n",
    "\n",
    "entity_feature_test=entity_data2\n",
    "#############################################################################\n",
    "#               ADDRESS DATAFRAME\n",
    "#############################################################################\n",
    "\n",
    "#Link the ADABOOST prediction with the input tag/label\n",
    "DF=link_outclass_intag(add_y_test_class,y_add_prediction_ada_test)\n",
    "#Join the prediction about the same input tag/label\n",
    "address_pred_feature_ada_test = join_dataframe_intag(DF,\"add\")\n",
    "\n",
    "#############################################################################\n",
    "#               MOTIFS-1 DATAFRAME\n",
    "#############################################################################\n",
    "\n",
    "#Link the ADABOOST prediction with the input tag/label\n",
    "DF=link_outclass_intag(mot1_y_class,y_mot1_prediction_ada_test)\n",
    "#Join the prediction about the same input tag/label\n",
    "motif1_pred_feature_ada_test = join_dataframe_intag(DF,\"mot1\")\n",
    "\n",
    "#############################################################################\n",
    "#               MOTIFS-2 DATAFRAME\n",
    "#############################################################################\n",
    "#Link the ADABOOST prediction with the input tag/label\n",
    "DF=link_outclass_intag(mot2_y_test_class,y_mot2_prediction_ada_test)\n",
    "#Join the prediction about the same input tag/label\n",
    "motif2_pred_feature_ada_test = join_dataframe_intag(DF,\"mot2\")\n",
    "\n",
    "#Join all the dataframe information\n",
    "\n",
    "#############################################################################\n",
    "#               ADABOOST DATAFRAME CREATION\n",
    "#############################################################################\n",
    "df_final_ada_test = entity_feature_test.join(address_pred_feature_ada_test,['user'])\n",
    "df_final_ada_test = df_final_ada_test.join(motif1_pred_feature_ada_test,['user'])\n",
    "df_final_ada_test  = df_final_ada_test.join(motif2_pred_feature_ada_test,['user'])\n",
    "#df_final_ada_test  = transform_label_to_id(df_final_ada_test ,\"label\",\"user\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "'path hdfs://10.200.5.25:9001/user/titanium/dataframe_join/df_final_ada_test already exists.;'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/opt/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o2325.save.\n: org.apache.spark.sql.AnalysisException: path hdfs://10.200.5.25:9001/user/titanium/dataframe_join/df_final_ada_test already exists.;\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:114)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:104)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:102)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:122)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:80)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:80)\n\tat org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:668)\n\tat org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:668)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:78)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:668)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:276)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:270)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:228)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-319a73c6f304>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"com.databricks.spark.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"header\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mpath_directory\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/df_final_ada_test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/spark/python/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, path, format, mode, partitionBy, **options)\u001b[0m\n\u001b[1;32m    734\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: 'path hdfs://10.200.5.25:9001/user/titanium/dataframe_join/df_final_ada_test already exists.;'"
     ]
    }
   ],
   "source": [
    "#############################################################\n",
    "#           STORE ADABOOST FEATURE IN HDFS\n",
    "#############################################################\n",
    "path_directory=\"/dataframe_join\"\n",
    "df_final_ada_test.write\\\n",
    ".format(\"com.databricks.spark.csv\")\\\n",
    ".option(\"header\", \"true\")\\\n",
    ".save(path+path_directory+\"/df_final_ada_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "#               ADDRESS DATAFRAME\n",
    "#############################################################################\n",
    "\n",
    "#Link the RANDOMFOREST prediction with the input tag/label\n",
    "DF=link_outclass_intag(add_y_test_class,y_add_prediction_rf_test)\n",
    "#Join the prediction about the same input tag/label\n",
    "address_pred_feature_rf_test = join_dataframe_intag(DF,\"add\")\n",
    "\n",
    "#############################################################################\n",
    "#               MOTIFS-1 DATAFRAME\n",
    "#############################################################################\n",
    "#Link the RANDOMFOREST prediction with the input tag/label\n",
    "DF=link_outclass_intag(mot1_y_class,y_mot1_prediction_rf_test)\n",
    "#Join the prediction about the same input tag/label\n",
    "motif1_pred_feature_rf_test = join_dataframe_intag(DF,\"mot1\")\n",
    "\n",
    "#############################################################################\n",
    "#               MOTIFS-2 DATAFRAME\n",
    "#############################################################################\n",
    "#Link the RANDOMFOREST prediction with the input tag/label\n",
    "DF=link_outclass_intag(mot2_y_test_class,y_mot2_prediction_rf_test)\n",
    "#Join the prediction about the same input tag/label\n",
    "motif2_pred_feature_rf_test = join_dataframe_intag(DF,\"mot2\")\n",
    "\n",
    "#############################################################################\n",
    "#               RANDOM FOREST DATAFRAME CREATION\n",
    "#############################################################################\n",
    "df_final_rf_test = entity_feature_test.join(address_pred_feature_rf_test,['user'])\n",
    "df_final_rf_test = df_final_rf_test.join(motif1_pred_feature_rf_test,['user'])\n",
    "df_final_rf_test = df_final_rf_test.join(motif2_pred_feature_rf_test,['user'])\n",
    "#df_final_rf_test = transform_label_to_id(df_final_rf_test,\"label\",\"user\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "#           STORE RANDOMFOREST FEATURE IN HDFS\n",
    "#############################################################\n",
    "path_directory=\"/dataframe_join\"\n",
    "\n",
    "df_final_rf_test.write\\\n",
    ".format(\"com.databricks.spark.csv\")\\\n",
    ".option(\"header\", \"true\")\\\n",
    ".save(path+path_directory+\"/df_final_rf_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_ada_test= sqlContext.read.format('com.databricks.spark.csv')\\\n",
    ".option('header','true')\\\n",
    ".option(\"inferSchema\", \"true\")\\\n",
    ".load(path+path_directory+\"/df_final_ada_test/\")\n",
    "\n",
    "df_final_rf_test= sqlContext.read.format('com.databricks.spark.csv')\\\n",
    ".option('header','true')\\\n",
    ".option(\"inferSchema\", \"true\")\\\n",
    ".load(path+path_directory+\"/df_final_rf_test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_ada_test=df_final_ada_test.fillna(0)\n",
    "df_final_rf_test=df_final_rf_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: integer (nullable = true)\n",
      " |-- user: string (nullable = true)\n",
      " |-- balance_recv: double (nullable = true)\n",
      " |-- balancein: double (nullable = true)\n",
      " |-- balance: double (nullable = true)\n",
      " |-- count_recv: integer (nullable = true)\n",
      " |-- count_sent: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "entity_data2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "#               ADABOOST DATAFRAME CREATION\n",
    "#############################################################################\n",
    "\n",
    "#Transform label to class index (output)\n",
    "#df_final_ada_test=transform_label_to_id(df_final_ada_test,\"label\",\"user\")\n",
    "ada_final_X_test0=entity_data2.select(\"balance_recv\",\"balancein\",\"balance\",\"count_recv\",\"count_sent\")\n",
    "\n",
    "#ada_final_X_test0=df_final_ada_test.select(\"balance_recv\",\"balancein\",\"balance\",\"count_recv\",\"count_sent\",\\\n",
    "#                        \"add_cnt0\",\"add_cnt1\",\"add_cnt2\",\"add_cnt3\",\\\n",
    "#                        \"mot1_cnt0\",\"mot1_cnt1\",\"mot1_cnt2\",\"mot1_cnt3\",\\\n",
    "#                        \"mot2_cnt0\",\"mot2_cnt1\",\"mot2_cnt2\",\"mot2_cnt3\")\n",
    "#Split the input from the output data\n",
    "\n",
    "\n",
    "ada_final_y_test0=entity_data2.select(\"label\")\n",
    "ada_final_y_test0 = ada_final_y_test0.withColumn(\"label\", f.col(\"label\").cast(\"string\"))\n",
    "#Round amount field\n",
    "ada_final_X_test0 = ada_final_X_test0.withColumn(\"balance_recv\", f.round(ada_final_X_test0[\"balance_recv\"], 6))\n",
    "ada_final_X_test0 = ada_final_X_test0.withColumn(\"balancein\", f.round(ada_final_X_test0[\"balancein\"], 6))\n",
    "ada_final_X_test0 = ada_final_X_test0.withColumn(\"balance\", f.round(ada_final_X_test0[\"balance\"], 6))\n",
    "\n",
    "#Transform input/output dataframe in vector\n",
    "ada_final_X_test0 = ada_final_X_test0.collect()\n",
    "ada_final_y_test0 = ada_final_y_test0.collect()\n",
    "\n",
    "#Reshape the output vector\n",
    "ada_final_y_test0=np.reshape(ada_final_y_test0,(len(ada_final_y_test0),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "#               RANDOMFOREST DATAFRAME CREATION\n",
    "#############################################################################\n",
    "\n",
    "#Transform label to class index (output)\n",
    "#df_final_rf_test=transform_label_to_id(df_final_rf_test,\"label\",\"user\")\n",
    "\n",
    "#Split the input from the output data\n",
    "rf_final_X_test0=df_final_rf_test.select(\"balance_recv\",\"balancein\",\"balance\",\"count_recv\",\"count_sent\",\\\n",
    "                        \"add_cnt0\",\"add_cnt1\",\"add_cnt2\",\"add_cnt3\",\\\n",
    "                        \"mot1_cnt0\",\"mot1_cnt1\",\"mot1_cnt2\",\"mot1_cnt3\",\\\n",
    "                        \"mot2_cnt0\",\"mot2_cnt1\",\"mot2_cnt2\",\"mot2_cnt3\")\n",
    "\n",
    "rf_final_y_test0=df_final_rf_test.select(\"label\")\n",
    "rf_final_y_test0 = rf_final_y_test0.withColumn(\"label\", f.col(\"label\").cast(\"string\"))\n",
    "\n",
    "#Round amount field\n",
    "rf_final_X_test0 = rf_final_X_test0.withColumn(\"balance_recv\", f.round(rf_final_X_test0[\"balance_recv\"], 6))\n",
    "rf_final_X_test0 = rf_final_X_test0.withColumn(\"balancein\", f.round(rf_final_X_test0[\"balancein\"], 6))\n",
    "rf_final_X_test0 = rf_final_X_test0.withColumn(\"balance\", f.round(rf_final_X_test0[\"balance\"], 6))\n",
    "\n",
    "#Transform input/output dataframe in vector\n",
    "rf_final_X_test0 = rf_final_X_test0.collect()\n",
    "rf_final_y_test0 = rf_final_y_test0.collect()\n",
    "\n",
    "#Reshape the output vector\n",
    "rf_final_y_test0=np.reshape(rf_final_y_test0,(len(rf_final_y_test0),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train=0; Test=70; Accuracy Adaboost:0.0\n"
     ]
    }
   ],
   "source": [
    "#############################################################################\n",
    "#               EVALUATION\n",
    "#############################################################################\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_prediction_ada_test = loaded_model_ada_final.predict(ada_final_X_test0)\n",
    "#y_prediction_rf_test= loaded_model_rfc_final.predict(rf_final_X_test0) \n",
    "\n",
    "#Accuracy with the same dataset\n",
    "print(\"Train=%s; Test=%s; Accuracy Adaboost:%s\" %(0,len(ada_final_X_test0 ),metrics.accuracy_score(ada_final_y_test0 , y_prediction_ada_test )))\n",
    "#print(\"Train=%s; Test=%s; Accuracy RandomForest:%s\" %(0,len(rf_final_X_test0 ),metrics.accuracy_score(rf_final_y_test0 , y_prediction_rf_test )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+------------------+------------------+--------------------+----------+----------+\n",
      "|label|                user|      balance_recv|         balancein|             balance|count_recv|count_sent|\n",
      "+-----+--------------------+------------------+------------------+--------------------+----------+----------+\n",
      "|    1|MercadoBitcoin.co...| 41708.98170726001| 51531.75953852001|  -9822.777831259998|      1766|       722|\n",
      "|    1|MercadoBitcoin.co...| 517.2303597899999| 544.5094150199999|  -27.27905523000004|       166|        57|\n",
      "|    1|        Cavirtex.com| 96502.01483320999|112073.87241775998| -15571.857584549987|      8017|      2870|\n",
      "|    1|          VirWoX.com|18595.922202779988|24146.342736819977|  -5550.420534039989|      3414|      1267|\n",
      "|    2|         BitZino.com| 7208.211132199999| 9635.911612120006| -2427.7004799200067|      2669|       810|\n",
      "|    1|          VirWoX.com| 90049.15396205007|115057.79711077994|  -25008.64314872987|      6210|      2490|\n",
      "|    1|       OrderBook.net| 3293.323561190001| 3043.387263529999|  249.93629766000186|       826|        73|\n",
      "|    1|        Cavirtex.com|15391.626051369998|16206.980879329998|       -815.35482796|      2409|       749|\n",
      "|    1|    BitBargain.co.uk|25.370500049999997|       26.10651763| -0.7360175800000022|        10|         6|\n",
      "|    1|      HappyCoins.com|           13.4601|           13.6795|-0.21940000000000026|        11|         9|\n",
      "+-----+--------------------+------------------+------------------+--------------------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "entity_data2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1' '1' '0' '1' '1' '1' '1' '0' '0' '0']\n"
     ]
    }
   ],
   "source": [
    "print(y_prediction_rf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
