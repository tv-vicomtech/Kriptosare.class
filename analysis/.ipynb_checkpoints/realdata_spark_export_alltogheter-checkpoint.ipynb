{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = 'pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/media/datasets/spark-2.4.0')\n",
    "from pyspark import SparkContext,SparkConf\n",
    "conf = (SparkConf()\n",
    "         .setMaster(\"spark://10.200.5.25:7077\")\n",
    "         .set(\"spark.driver.host\",\"10.200.5.25\") \n",
    "         .set(\"spark.executor.memory\",\"25g\")\n",
    "         .set('spark.driver.memory', '30G')\n",
    "         .setAppName(\"newanalysis\"))\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import binascii\n",
    "from pyspark.sql import SQLContext\n",
    "from functools import reduce\n",
    "#import pygraphviz\n",
    "import pyspark.sql.functions as f\n",
    "from IPython.display import Image\n",
    "#from networkx.drawing.nx_pydot import write_dot\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"hdfs://10.200.5.25:9001/user/titanium/\"\n",
    "pathDir =\"analysis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Definition\n",
    "# 1: exchange\n",
    "# 2: gambling\n",
    "# 3: market\n",
    "# 4: service\n",
    "# 5: pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "#            LOAD LABEL\n",
    "#############################################################\n",
    "dirt=[\"exchange\",\"gambling\",\"market\",\"service\",\"pool\"]\n",
    "df_label_load_part=[None]*5\n",
    "for i in range(0,len(dirt)):\n",
    "    df_label_load_part[i] = sqlContext.read\\\n",
    "             .format(\"com.databricks.spark.csv\")\\\n",
    "             .option(\"header\", \"true\")\\\n",
    "             .option(\"inferSchema\", \"true\")\\\n",
    "             .load(path+\"walletexp_data/\"+dirt[i]+\"/*.csv\")\n",
    "    df_label_load_part[i] =df_label_load_part[i].withColumn(\"xxx\",f.lit(i+1))\n",
    "\n",
    "df_label_load=df_label_load_part[0]\n",
    "df_label_load=df_label_load.union(df_label_load_part[1])\n",
    "df_label_load=df_label_load.union(df_label_load_part[2])\n",
    "df_label_load=df_label_load.union(df_label_load_part[3])\n",
    "df_label_load=df_label_load.union(df_label_load_part[4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label_load = df_label_load.groupby(\"address\").agg(f.first(\"label\").alias(\"label\"),f.first(\"xxx\").alias(\"class\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "#           REMOVE DUPLICATE LABEL DATAFRAME\n",
    "#############################################################\n",
    "df_label=df_label_load.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "#            LOAD TRANSACTIONS\n",
    "#############################################################\n",
    "# 1- 4\n",
    "# 4\n",
    "# 5\n",
    "# 6\n",
    "# 7\n",
    "# 8\n",
    "# 9-11\n",
    "for i in range(9,11):\n",
    "    df_transactions_part = sqlContext.read\\\n",
    "             .format(\"csv\")\\\n",
    "             .option(\"header\", \"true\")\\\n",
    "             .option(\"inferSchema\", \"true\")\\\n",
    "             .load(path+\"transaction/part\"+str(i))\n",
    "    if(i==9):\n",
    "        df_transactions=df_transactions_part\n",
    "    else:\n",
    "        df_transactions=df_transactions.union(df_transactions_part)\n",
    "\n",
    "        \n",
    "#############################################################\n",
    "#            LOAD TRANSACTIONS\n",
    "#############################################################\n",
    "df_transactions = sqlContext.read\\\n",
    "             .format(\"csv\")\\\n",
    "             .option(\"header\", \"true\")\\\n",
    "             .option(\"inferSchema\", \"true\")\\\n",
    "             .load(path+\"transaction/part6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "#           OUTPUT ADDRESS DATAFRAME CREATION\n",
    "#############################################################\n",
    "df_output_addresses = df_transactions.select('address','vout_idx','amount','tx_id','tx_hash','size','coinbase','height')\n",
    "\n",
    "#############################################################\n",
    "#           REMOVE DUPLICATE OUTPUT DATAFRAME\n",
    "#############################################################\n",
    "df_output_addresses=df_output_addresses.dropDuplicates(['address','vout_idx','amount','tx_id'])\n",
    "\n",
    "#############################################################\n",
    "#   INPUT ADDRESS DATAFRAME CREATION AND REMOVE DUPLICATE\n",
    "#############################################################\n",
    "df_input_addresses=df_transactions.dropDuplicates([\"vin_txid\", \"vin_vout\"])\n",
    "df_input_addresses=df_input_addresses.alias('a')\\\n",
    ".join(df_output_addresses.alias('b'),(f.col('a.vin_txid') == f.col('b.tx_id')) & (f.col('a.vin_vout') == f.col('b.vout_idx')),\"leftouter\")\\\n",
    ".select(f.col('b.address'),f.col('a.vin_vout'),f.col('b.amount'),f.col('a.tx_id').alias('tx_id'),f.col('b.tx_hash'),f.col('b.coinbase'),f.col('b.height'),f.col('b.size'))\n",
    "\n",
    "#############################################################\n",
    "#           JOIN ADDRESSES IN/OUT WITH LABEL DATAFRAME\n",
    "#############################################################\n",
    "df_output_addresses_tag=df_output_addresses.alias('a')\\\n",
    ".join(df_label.alias('b'),(f.col('a.address') == f.col('b.address')),\"leftouter\")\\\n",
    ".select(f.col('b.class').alias(\"class\"),f.col('b.label').alias(\"user\"),f.col('a.address'),f.col('a.amount'),f.col('a.coinbase'),f.col('a.tx_id'),f.col('a.vout_idx'),f.col('a.height'))\n",
    "df_input_addresses_tag=df_input_addresses.alias('a')\\\n",
    ".join(df_label.alias('b'),(f.col('b.address') == f.col('a.address')),\"leftouter\")\\\n",
    ".select(f.col('b.class').alias(\"class\"),f.col('b.label').alias(\"user\"),f.col('a.address'),f.col('a.amount'),f.col('a.coinbase'),f.col('a.tx_id'),f.col('a.vin_vout').alias('vout_idx'))\n",
    "\n",
    "df_output_addresses_tag.count()\n",
    "df_input_addresses_tag.count()\n",
    "\n",
    "df_output_addresses_tag_copy =df_output_addresses_tag.groupby(\"tx_id\").agg(f.count(\"address\").alias(\"cnt_out\"))\n",
    "\n",
    "tx_input_schema = df_input_addresses_tag.groupby(\"tx_id\").agg(f.count(\"address\").alias(\"cnt_in\"))\n",
    "\n",
    "########################################################################\n",
    "df_output_addresses_tag_copy=df_output_addresses_tag_copy.alias('a')\\\n",
    ".join(tx_input_schema.alias('b'),['tx_id'],'leftouter')\\\n",
    ".select(f.col('b.cnt_in'),f.col('a.cnt_out'),f.col('a.tx_id'))\n",
    "\n",
    "df_output_addresses_tag_copy.count()\n",
    "\n",
    "df_output_addresses_tag = df_output_addresses_tag.alias(\"a\")\\\n",
    ".join(df_output_addresses_tag_copy.alias('b'),['tx_id'],'leftouter')\\\n",
    ".select(f.col('b.cnt_in'),f.col('b.cnt_out'),f.col('a.user'),f.col('a.class'),f.col('a.address'),f.col('a.amount'),f.col('a.coinbase'),f.col('a.tx_id'),f.col('a.vout_idx'),f.col('a.height'))\n",
    "\n",
    "first_show=df_output_addresses_tag.groupby(\"address\").agg(f.min(\"height\").alias(\"show\"))\n",
    "\n",
    "df_output_addresses_tag = df_output_addresses_tag.alias(\"a\")\\\n",
    ".join(first_show.alias('b'),['address'],'leftouter')\\\n",
    ".select(f.col('b.show'),f.col('a.cnt_in'),f.col('a.cnt_out'),f.col('a.class'),f.col('a.user'),f.col('a.address'),f.col('a.amount'),f.col('a.coinbase'),f.col('a.tx_id'),f.col('a.vout_idx'),f.col('a.height')).cache()\n",
    "\n",
    "df_output_addresses_tag.count()\n",
    "\n",
    "df_output_addresses_tag=df_output_addresses_tag.withColumn(\"first\",f.when(f.col(\"show\")==f.col(\"height\"),1).otherwise(0)).drop(\"show\")\n",
    "\n",
    "df_output_addresses_tag.write.parquet(path+pathDir+\"/df_output_addresses_tag9.parquet\")\n",
    "df_input_addresses_tag.write.parquet(path+pathDir+\"/df_input_addresses_tag9.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input_addresses_tag= sqlContext.read.parquet(path+pathDir+\"/df_input_addresses_tag1.parquet\")\n",
    "#df_input_addresses_tag2= sqlContext.read.parquet(path+pathDir+\"/df_input_addresses_tag2.parquet\")\n",
    "#df_input_addresses_tag= df_input_addresses_tag.union(df_input_addresses_tag2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_addresses_tag= sqlContext.read.parquet(path+pathDir+\"/df_output_addresses_tag1.parquet\")\n",
    "#df_output_addresses_tag2= sqlContext.read.parquet(path+pathDir+\"/df_output_addresses_tag2.parquet\")\n",
    "#df_output_addresses_tag=df_output_addresses_tag.union(df_output_addresses_tag2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_addresses_tag.printSchema()\n",
    "row1 = df_output_addresses_tag.agg({\"height\": \"min\"}).collect()[0]\n",
    "row2 = df_output_addresses_tag.agg({\"height\": \"max\"}).collect()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(row1)\n",
    "print(row2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3,10):\n",
    "    df_output_addresses_tag= sqlContext.read.parquet(path+pathDir+\"/df_output_addresses_tag\"+str(i)+\".parquet\")\n",
    "    df_input_addresses_tag= sqlContext.read.parquet(path+pathDir+\"/df_input_addresses_tag\"+str(i)+\".parquet\")\n",
    "\n",
    "    df_output_addresses_tag_reduced=df_output_addresses_tag.fillna(\"Unknow\",subset=[\"user\"])\n",
    "    df_input_addresses_tag_reduced=df_input_addresses_tag.fillna(\"Unknow\",subset=[\"user\"])\n",
    "    #############################################################\n",
    "    #   Aggregate input and output labeled dataframe for distinct address\n",
    "    #############################################################\n",
    "\n",
    "    df_output_addresses_tag_grpby_addr=df_output_addresses_tag_reduced.groupby(df_output_addresses_tag_reduced.address)\\\n",
    "    .agg(f.count('address').alias(\"count\"),(f.sum('amount')).alias(\"totamount\"),f.first(f.col(\"user\")).alias(\"user\"),f.first(f.col(\"class\")).alias(\"class\"))\n",
    "    df_input_addresses_tag_grpby_addr=df_input_addresses_tag_reduced.groupby(df_input_addresses_tag_reduced.address)\\\n",
    "    .agg(f.count('address').alias(\"count\"),(f.sum('amount')).alias(\"totamount\"),f.first(f.col(\"user\")).alias(\"user\"),f.first(f.col(\"class\")).alias(\"class\"))\n",
    "\n",
    "    df_output_addresses_tag_grpby_addr =df_output_addresses_tag_grpby_addr.withColumn(\"totamount\",f.round(f.col(\"totamount\"))/100000000)\n",
    "    df_input_addresses_tag_grpby_addr =df_input_addresses_tag_grpby_addr.withColumn(\"totamount\",f.round(f.col(\"totamount\"))/100000000)\n",
    "\n",
    "    df_output_addresses_tag_grpby_addr.count()\n",
    "    df_input_addresses_tag_grpby_addr.count()\n",
    "\n",
    "    #############################################################\n",
    "    # Aggregate input and output labeled dataframe for distinct user\n",
    "    #############################################################\n",
    "\n",
    "    df_output_addresses_tag_grpby_user=df_output_addresses_tag_grpby_addr.groupby(df_output_addresses_tag_grpby_addr.user)\\\n",
    "    .agg(f.count('address').alias(\"naddress\"),f.sum('totamount').alias(\"balancerecv\"))\n",
    "    df_input_addresses_tag_grpby_user=df_input_addresses_tag_grpby_addr.groupby(df_input_addresses_tag_grpby_addr.user)\\\n",
    "    .agg(f.count('address').alias(\"naddress\"),f.sum('totamount').alias(\"balancesend\"))\n",
    "\n",
    "\n",
    "    df_input_addresses_tag_grpby_user=df_input_addresses_tag_grpby_user.where(f.col(\"user\")!=\"Unknow\")\n",
    "    df_output_addresses_tag_grpby_user=df_output_addresses_tag_grpby_user.where(f.col(\"user\")!=\"Unknow\")\n",
    "\n",
    "    df_input_addresses_tag_grpby_user.count()\n",
    "    df_output_addresses_tag_grpby_user.count()\n",
    "\n",
    "    #############################################################\n",
    "    #           BALANCE ESTIMATION\n",
    "    #############################################################\n",
    "    # Retrive user in label dataframe that are not present into the input/output dataframe\n",
    "    list_unique_input_user=df_input_addresses_tag_grpby_user.groupby(\"user\").agg(f.first(\"user\").alias(\"unique\")).drop(\"user\")\n",
    "    list_unique_output_user=df_output_addresses_tag_grpby_user.groupby(\"user\").agg(f.first(\"user\").alias(\"unique\")).drop(\"user\")\n",
    "\n",
    "    # Add retrived user into the input/output dataframe (with default parameters)\n",
    "    user_out_toadd=list_unique_input_user.alias(\"a\").join(list_unique_output_user.alias(\"b\"),f.col(\"a.unique\")==f.col(\"b.unique\"),\"left_anti\")\n",
    "    user_in_toadd=list_unique_output_user.alias(\"a\").join(list_unique_input_user.alias(\"b\"),f.col(\"a.unique\")==f.col(\"b.unique\"),\"left_anti\")\n",
    "\n",
    "    #Add missing user in the input and output dataframe in order to calculate an estimation of the balance\n",
    "    user_in_toadd = user_in_toadd.withColumn(\"naddress\", f.lit(0))\n",
    "    user_in_toadd = user_in_toadd.withColumn(\"balancein\", f.lit(0))\n",
    "\n",
    "    df_input_addresses_tag_grpby_user_filled = df_input_addresses_tag_grpby_user.union(user_in_toadd)\n",
    "\n",
    "    user_out_toadd = user_out_toadd.withColumn(\"naddress\", f.lit(0))\n",
    "    user_out_toadd = user_out_toadd.withColumn(\"balanceout\", f.lit(0))\n",
    "    df_output_addresses_tag_grpby_user_filled = df_output_addresses_tag_grpby_user.union(user_out_toadd)\n",
    "\n",
    "\n",
    "    #############################################################\n",
    "    #           BALANCE ESTIMATION\n",
    "    #############################################################\n",
    "\n",
    "    df_user_balance=df_output_addresses_tag_grpby_user_filled.alias('a')\\\n",
    "    .join(df_input_addresses_tag_grpby_user_filled.alias('b'),\"user\",\"leftouter\")\\\n",
    "    .select(f.col('a.user'),f.col('a.balancerecv'),f.col('b.balancesend'))\n",
    "    df_user_balance=df_user_balance.fillna(0,subset=[\"balancerecv\",\"balancesend\"])\n",
    "    df_user_balance=df_user_balance.withColumn(\"balance\",f.col(\"balancerecv\")-f.col(\"balancesend\"))\\\n",
    "    .sort(f.col(\"balance\").desc())\n",
    "    df_user_balance = df_user_balance.withColumn(\"balance\",f.when(f.abs(f.col(\"balance\"))<0.00000001,0).otherwise(f.col(\"balance\")))\n",
    "\n",
    "    df_user_balance.count()\n",
    "    #############################################################\n",
    "    #           COMPUTE ADDRESS FEATURE\n",
    "    #############################################################\n",
    "\n",
    "    address_feature=df_output_addresses_tag_grpby_addr.alias(\"a\")\\\n",
    "    .join(df_input_addresses_tag_grpby_addr.alias(\"b\"),f.col(\"a.address\")==f.col(\"b.address\"),\"outer\")\\\n",
    "    .select(f.col('a.class').alias(\"a3\"),f.col('b.class').alias(\"b3\"),f.col('a.address').alias(\"a1\"),f.col('b.address').alias(\"b1\"),f.col('a.user').alias(\"a2\"),f.col('b.user').alias(\"b2\"),f.col('a.count').alias(\"count_rec\"),f.col('a.totamount').alias(\"totamount_rec\"),f.col('b.count').alias(\"count_sent\"),f.col('b.totamount').alias(\"totamount_sent\"))\n",
    "    address_feature=address_feature.withColumn(\"address\",f.when(f.col(\"a1\").isNotNull(),f.col(\"a1\")).otherwise(f.col(\"b1\")))\\\n",
    "    .drop(\"a1\",\"b1\")\n",
    "    address_feature=address_feature.withColumn(\"user\",f.when(f.col(\"a2\").isNotNull(),f.col(\"a2\")).otherwise(f.col(\"b2\")))\\\n",
    "    .drop(\"a2\",\"b2\")\n",
    "    address_feature=address_feature.withColumn(\"class\",f.when(f.col(\"a3\").isNotNull(),f.col(\"a3\")).otherwise(f.col(\"b3\")))\\\n",
    "    .drop(\"a3\",\"b3\")\n",
    "    address_feature=address_feature.fillna(0)\n",
    "    address_feature=address_feature.withColumn(\"balance\",f.col(\"totamount_rec\")-f.col(\"totamount_sent\"))\n",
    "    address_feature=address_feature.withColumn(\"unique\",f.when((f.col(\"count_rec\")<2)&(f.col(\"count_sent\")<2),1).otherwise(0))\n",
    "\n",
    "    address_feature=address_feature.alias(\"a\")\\\n",
    "    .join(df_output_addresses_tag_grpby_user.alias(\"b\"),f.col(\"a.user\")==f.col(\"b.user\"),\"leftouter\")\\\n",
    "    .select(f.col('a.class'),f.col('a.address'),f.col('a.user'),f.col('a.count_rec'),f.col(\"totamount_rec\"),f.col('a.count_sent'),f.col('a.totamount_sent'),f.col('a.balance'),f.col('a.unique'),f.col('b.naddress').alias('sibling'))\n",
    "    address_feature=address_feature.fillna(0)\n",
    "    address_feature=address_feature.where(f.col(\"user\")!=\"Unknow\")\n",
    "    #address_feature.count()\n",
    "\n",
    "    address_feature.write.parquet(path+pathDir+\"/address_feature\"+str(i)+\".parquet\")\n",
    "\n",
    "    #############################################################\n",
    "    #           COMPUTE ENTITY FEATURE\n",
    "    #############################################################\n",
    "    entity_feature=df_user_balance.alias(\"a\")\\\n",
    "    .join(df_output_addresses_tag_reduced.groupBy(\"user\").agg(f.countDistinct(\"address\").alias(\"add_recv\"),f.countDistinct(\"tx_id\").alias(\"count_recv\")).alias(\"b\"),f.col(\"a.user\")==f.col(\"b.user\"),\"leftouter\")\\\n",
    "    .select(f.col('a.user'),f.col('a.balancerecv'),f.col('a.balancesend'),f.col('a.balance'),f.col('b.count_recv'),f.col('b.add_recv'))\n",
    "    entity_feature=entity_feature.alias(\"a\")\\\n",
    "    .join(df_input_addresses_tag_reduced.groupBy(\"user\").agg(f.countDistinct(\"address\").alias(\"add_sent\"),f.countDistinct(\"tx_id\").alias(\"count_sent\")).alias(\"b\"),f.col(\"a.user\")==f.col(\"b.user\"),\"leftouter\")\\\n",
    "    .select(f.col('a.user'),f.col('a.balancerecv'),f.col('a.balancesend'),f.col('a.balance'),f.col('a.count_recv'),f.col('b.count_sent'),f.col('a.add_recv'),f.col('b.add_sent'))\n",
    "\n",
    "    entity_feature=entity_feature.fillna(0,subset=[\"count_recv\",\"count_sent\"])\n",
    "    entity_feature=entity_feature.where(f.col(\"user\")!=\"Unknow\")\n",
    "\n",
    "    entity_feature= entity_feature.alias('a').join(df_label.groupby(\"label\").agg(f.first(\"class\").alias(\"class\"))\\\n",
    "        .alias('b'),f.col(\"a.user\")==f.col(\"b.label\"),\"leftouter\")\\\n",
    "        .select(\"b.class\",\"a.user\",\"a.balancerecv\",\"a.balancesend\",\"a.balance\",\"a.count_recv\",\"a.count_sent\",'a.add_recv','a.add_sent')\n",
    "    entity_feature = entity_feature.withColumnRenamed(\"class\",\"label\")\n",
    "    entity_feature.count()\n",
    "\n",
    "    entity_feature.write.parquet(path+pathDir+\"/entity_feature\"+str(i)+\".parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(9,10):\n",
    "    if(j==9):\n",
    "        for i in range(9,11):\n",
    "            df_transactions_part = sqlContext.read\\\n",
    "                     .format(\"csv\")\\\n",
    "                     .option(\"header\", \"true\")\\\n",
    "                     .option(\"inferSchema\", \"true\")\\\n",
    "                     .load(path+\"transaction/part\"+str(i))\n",
    "            if(i==9):\n",
    "                df_transactions=df_transactions_part\n",
    "            else:\n",
    "                df_transactions=df_transactions.union(df_transactions_part)\n",
    "    else:\n",
    "        df_transactions = sqlContext.read\\\n",
    "                     .format(\"csv\")\\\n",
    "                     .option(\"header\", \"true\")\\\n",
    "                     .option(\"inferSchema\", \"true\")\\\n",
    "                     .load(path+\"transaction/part\"+str(j))\n",
    "\n",
    "    #Prepare a basic dataframe with all transaction-user-address information\n",
    "    df_transactions_general = df_transactions.alias('a').join(df_label.alias('b'),f.col('a.address')==f.col('b.address'),\"leftouter\")\\\n",
    "    .select(f.col(\"a.height\"),f.col(\"a.coinbase\"),f.col(\"a.timestamp\"),f.col(\"a.tx_id\"),f.col(\"a.tx_number\"),f.col(\"a.address\"),f.col(\"a.amount\"),f.col(\"a.vout_idx\"),f.col(\"a.vin_txid\"),f.col(\"a.vin_vout\"),f.col(\"b.label\").alias(\"outuser\"),f.col(\"b.class\").alias(\"class\")).cache()\n",
    "    df_transactions_general.count()\n",
    "\n",
    "    #Calculate the input amount of each transaction from each inuser\n",
    "    df_transactions_general_join_amount = df_transactions_general.groupBy(\"tx_id\",\"address\",\"vout_idx\").agg(f.first(\"amount\").alias(\"unique_amount\"),f.first(\"outuser\").alias(\"inuser\"))\n",
    "\n",
    "    #Join amount information with the basic dataframe information\n",
    "    df_transactions_general_information = df_transactions_general.alias('a').join(df_transactions_general_join_amount.alias('b'),(f.col('a.vin_txid')==f.col('b.tx_id'))&(f.col('a.vin_vout')==f.col('b.vout_idx')),\"leftouter\")\\\n",
    "    .select(f.col(\"a.height\"),f.col(\"a.coinbase\"),f.col(\"a.timestamp\"),f.col(\"a.tx_id\"),f.col(\"a.amount\"),f.col(\"a.outuser\"),f.col(\"a.class\"),f.col(\"a.address\"),f.col(\"a.vin_txid\"),f.col(\"a.vin_vout\"),f.col(\"b.unique_amount\").alias(\"amount_sent\"),f.col(\"b.address\").alias(\"address_sent\"),f.col(\"b.inuser\").alias(\"inuser_old\"))\n",
    "\n",
    "    #Remove outuser with null field\n",
    "    df_transactions_general_information = df_transactions_general_information.filter(f.col(\"outuser\").isNotNull())\n",
    "\n",
    "    #Remove substitute inuser null information with Coinbase information\n",
    "    df_transactions_general_information = df_transactions_general_information.withColumn(\"inuser\",f.when((f.col(\"inuser_old\").isNull())&(f.col(\"address\").isNotNull()),\"Coinbase\").otherwise(f.col(\"inuser_old\")))\n",
    "    df_transactions_general_information = df_transactions_general_information.drop(f.col(\"inuser_old\")).cache()\n",
    "    df_transactions_general_information.count()\n",
    "\n",
    "    #Inuser-Outuser dataframe with count distinct transaction\n",
    "    df_inuser_outuser_numtx = df_transactions_general_information.groupby(\"outuser\",\"inuser\").agg(f.countDistinct(\"tx_id\"))\n",
    "\n",
    "    #############################################################\n",
    "    #           COMPUTE MOTIFS1 FEATURE\n",
    "    #############################################################\n",
    "\n",
    "    motifs_1 = df_transactions_general_information.groupBy(\"outuser\",\"inuser\",'tx_id').agg(f.countDistinct(\"address\").alias(\"address_recv_dist\"),f.first(\"class\").alias(\"class\"))\\\n",
    "    .select(\"class\",\"outuser\",\"inuser\",'tx_id',\"address_recv_dist\").cache()\n",
    "\n",
    "    #Calculate out amount of each user (in-out) in each transactions\n",
    "    amount_out_processing = df_transactions_general_information.groupBy(\"outuser\",\"inuser\",\"tx_id\",\"address\").agg(f.first(\"amount\").alias(\"amount_recv\"))\\\n",
    "    .groupBy(\"outuser\",\"inuser\",\"tx_id\").agg(f.sum(\"amount_recv\").alias(\"amount_recv\"))\n",
    "    amount_out_processing=amount_out_processing.fillna(\"Unknow\")\n",
    "    #Calculate in amount of each user (in-out) in each transactions\n",
    "    amount_in_processing = df_transactions_general_information.groupBy(\"outuser\",\"inuser\",\"tx_id\").agg(f.count(\"vin_txid\").alias(\"tx_sent\"),f.sum(\"amount_sent\").alias(\"amount_sent\"),f.countDistinct(\"address_sent\").alias(\"address_sent\"))\\\n",
    "    .groupBy(\"outuser\",\"inuser\",\"tx_id\").agg(f.sum(\"tx_sent\").alias(\"tx_sent\"),f.sum(\"amount_sent\").alias(\"amount_sent\"),f.sum(\"address_sent\").alias(\"address_sent_dist\"))\n",
    "    amount_in_processing=amount_in_processing.fillna(\"Unknow\")\n",
    "\n",
    "\n",
    "    #Calculate out amount of each transactions\n",
    "    amount_out_processing_tx = amount_out_processing.groupBy(\"tx_id\").agg(f.sum(\"amount_recv\").alias(\"total_recv_amount\"))\n",
    "    #Calculate in amount of each transactions\n",
    "    amount_in_processing_tx = df_transactions_general_information.groupBy(\"tx_id\",\"vin_txid\",\"vin_vout\").agg(f.first(\"amount_sent\").alias(\"amount_sent\"))\\\n",
    "    .groupBy(\"tx_id\").agg(f.sum(\"amount_sent\").alias(\"total_sent_amount\"))\n",
    "    amount_out_processing=amount_out_processing.fillna(\"Unknow\")\n",
    "    amount_out_processing.count()\n",
    "\n",
    "    #Calculate fee in each transaction\n",
    "    fee_tx = amount_out_processing_tx.alias('a').join(amount_in_processing_tx.alias('b'), f.col(\"a.tx_id\")==f.col(\"b.tx_id\"))\\\n",
    "    .select(\"a.tx_id\",\"total_recv_amount\",\"total_sent_amount\")\n",
    "    fee_tx = fee_tx.withColumn(\"fees\",f.col(\"total_sent_amount\")-f.col(\"total_recv_amount\"))\n",
    "\n",
    "    #Join all dataframe information to a unique dataframe for motifs-1\n",
    "    motifs_1 = motifs_1.alias(\"a\").join(amount_out_processing.alias(\"b\"),(f.col(\"a.outuser\")==f.col(\"b.outuser\"))&(f.col(\"a.inuser\")==f.col(\"b.inuser\"))&(f.col(\"a.tx_id\")==f.col(\"b.tx_id\")))\\\n",
    "    .select(\"a.class\",\"a.outuser\",\"a.inuser\",\"a.tx_id\",\"address_recv_dist\",\"amount_recv\")\n",
    "    motifs_1 = motifs_1.alias(\"a\").join(amount_in_processing.alias(\"b\"),(f.col(\"a.outuser\")==f.col(\"b.outuser\"))&(f.col(\"a.inuser\")==f.col(\"b.inuser\"))&(f.col(\"a.tx_id\")==f.col(\"b.tx_id\")))\\\n",
    "    .select(\"a.class\",\"a.outuser\",\"a.inuser\",\"a.tx_id\",\"a.address_recv_dist\",\"a.amount_recv\",\"b.tx_sent\",\"b.address_sent_dist\",\"amount_sent\")\n",
    "    motifs_1=motifs_1.alias('a').join(motifs_1.groupBy(\"outuser\",\"inuser\").agg(f.countDistinct(\"tx_id\").alias(\"tx_recv_tot\")).fillna(\"Unknow\").alias('b'),(f.col(\"a.outuser\")==f.col(\"b.outuser\"))&(f.col(\"a.inuser\")==f.col(\"b.inuser\")))\\\n",
    "    .select(\"a.class\",\"a.outuser\",\"a.inuser\",\"a.tx_id\",\"a.address_recv_dist\",\"a.amount_recv\",\"a.tx_sent\",\"a.address_sent_dist\",\"a.amount_sent\",\"tx_recv_tot\")\n",
    "    motifs_1=motifs_1.alias('a').join(fee_tx.alias('b'),(f.col(\"a.tx_id\")==f.col(\"b.tx_id\")))\\\n",
    "    .select(\"a.class\",\"a.outuser\",\"a.inuser\",\"a.tx_id\",\"a.address_recv_dist\",\"a.amount_recv\",\"a.tx_sent\",\"a.address_sent_dist\",\"a.amount_sent\",\"a.tx_recv_tot\",\"b.fees\")\n",
    "\n",
    "    #Define relation between user loop or direct\n",
    "    motifs_1 = motifs_1.withColumn(\"loop_in_out\", f.when(f.col(\"outuser\")==f.col(\"inuser\"),1).otherwise(0))\n",
    "    motifs_1 = motifs_1.withColumn(\"direct_in_out\", f.when(f.col(\"outuser\")==f.col(\"inuser\"),0).otherwise(1)).cache()\n",
    "\n",
    "    #Set to 0 where find null\n",
    "    motifs_1 = motifs_1.fillna(0,subset=['amount_sent','fees'])\n",
    "    motifs_1.count()\n",
    "\n",
    "    motifs_1.write.parquet(path+pathDir+\"/motifs1_\"+str(j)+\".parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(9,10):\n",
    "    if(j==9):\n",
    "        for i in range(9,11):\n",
    "            df_transactions_part = sqlContext.read\\\n",
    "                     .format(\"csv\")\\\n",
    "                     .option(\"header\", \"true\")\\\n",
    "                     .option(\"inferSchema\", \"true\")\\\n",
    "                     .load(path+\"transaction/part\"+str(i))\n",
    "            if(i==9):\n",
    "                df_transactions=df_transactions_part\n",
    "            else:\n",
    "                df_transactions=df_transactions.union(df_transactions_part)\n",
    "    else:\n",
    "        df_transactions = sqlContext.read\\\n",
    "                     .format(\"csv\")\\\n",
    "                     .option(\"header\", \"true\")\\\n",
    "                     .option(\"inferSchema\", \"true\")\\\n",
    "                     .load(path+\"transaction/part\"+str(j))\n",
    "\n",
    "#############################################################\n",
    "#           COMPUTE MOTIFS2 FEATURE\n",
    "#############################################################\n",
    "    #Prepare a basic dataframe with all transaction-user-address information\n",
    "    df_transactions_general = df_transactions.alias('a').join(df_label.alias('b'),f.col('a.address')==f.col('b.address'),\"leftouter\")\\\n",
    "    .select(f.col(\"a.height\"),f.col(\"a.coinbase\"),f.col(\"a.timestamp\"),f.col(\"a.tx_id\"),f.col(\"a.tx_number\"),f.col(\"a.address\"),f.col(\"a.amount\"),f.col(\"a.vout_idx\"),f.col(\"a.vin_txid\"),f.col(\"a.vin_vout\"),f.col(\"b.label\").alias(\"outuser\"),f.col(\"b.class\").alias(\"class\")).cache()\n",
    "    df_transactions_general.count()\n",
    "    \n",
    "    #Create dataframe with all information without repeating, and remove \"null\" user (clone)\n",
    "    df_transactions_general_join_motifs2 = df_transactions_general.groupBy(\"tx_id\",\"address\",\"vout_idx\")\\\n",
    "    .agg(f.first(\"outuser\").alias(\"miduser\"),f.first(\"vin_txid\").alias(\"vin_txid\"),f.first(\"vin_vout\").alias(\"vin_vout\"))\n",
    "    #.agg(f.first(\"amount\").alias(\"unique_amount\"),f.first(\"outuser\").alias(\"miduser\"),f.first(\"vin_txid\").alias(\"vin_txid\"),f.first(\"vin_vout\").alias(\"vin_vout\"))\n",
    "    #df_transactions_general_join_motifs2 = df_transactions_general_join_motifs2.filter(f.col(\"miduser\").isNotNull())\n",
    "\n",
    "\n",
    "    #Join the previuos dataframe with the dataframe general in order to obtain 1-motifs\n",
    "    df_transactions_general_information2 = df_transactions_general.alias('a').join(df_transactions_general_join_motifs2.alias('b'),(f.col('a.vin_txid')==f.col('b.tx_id'))&(f.col('a.vin_vout')==f.col('b.vout_idx')),\"leftouter\")\\\n",
    "    .select(f.col(\"a.tx_id\"),f.col(\"a.outuser\"),f.col(\"a.address\"),f.col(\"a.vin_txid\").alias(\"tx_id_mid\"),f.col(\"a.vin_vout\").alias(\"vin_vout_idx_mid\"),f.col(\"b.vin_txid\").alias(\"tx_id_in\"),f.col(\"b.vin_vout\").alias(\"vin_vout_idx_in\"),f.col(\"b.miduser\"))\n",
    "    #.select(f.col(\"a.height\"),f.col(\"a.coinbase\"),f.col(\"a.timestamp\"),f.col(\"a.tx_id\"),f.col(\"a.amount\"),f.col(\"a.outuser\"),f.col(\"a.address\"),f.col(\"a.vin_txid\").alias(\"tx_id_mid\"),f.col(\"a.vin_vout\").alias(\"vin_vout_idx_mid\"),f.col(\"b.vin_txid\").alias(\"tx_id_in\"),f.col(\"b.vin_vout\").alias(\"vin_vout_idx_in\"),f.col(\"b.unique_amount\").alias(\"amount_mid\"),f.col(\"b.address\").alias(\"address_mid\"),f.col(\"b.miduser\"))\n",
    "\n",
    "    #Repeat the previuos operation in order to obtain 2-motifs\n",
    "    df_transactions_general_info_deep = df_transactions_general_information2.alias('a').join(df_transactions_general_join_motifs2.alias('b'),(f.col('a.tx_id_in')==f.col('b.tx_id'))&(f.col('a.vin_vout_idx_in')==f.col('b.vout_idx')),\"leftouter\")\\\n",
    "    .select(f.col(\"a.tx_id\"),f.col(\"a.outuser\"),f.col(\"a.address\"),f.col(\"a.tx_id_mid\"),f.col(\"a.miduser\"),f.col(\"b.miduser\").alias(\"inuser_old\"))\n",
    "    #.select(f.col(\"a.height\"),f.col(\"a.timestamp\"),f.col(\"a.tx_id\"),f.col(\"a.amount\"),f.col(\"a.outuser\"),f.col(\"a.address\"),f.col(\"a.tx_id_mid\"),f.col(\"a.vin_vout_idx_mid\"),f.col(\"a.amount_mid\"),f.col(\"a.address_mid\"),f.col(\"a.miduser\"),f.col(\"b.unique_amount\").alias(\"amount_sent\"),f.col(\"b.address\").alias(\"address_sent\"),f.col(\"b.miduser\").alias(\"inuser_old\"))\n",
    "\n",
    "    #Remove null user\n",
    "    df_transactions_general_info_deep = df_transactions_general_info_deep.filter(f.col(\"outuser\").isNotNull())\n",
    "    df_transactions_general_info_deep = df_transactions_general_info_deep.filter(f.col(\"miduser\").isNotNull())\n",
    "\n",
    "    #Change null user but with address with \"Coinbase\"\n",
    "    df_transactions_general_info_deep = df_transactions_general_info_deep.withColumn(\"inuser\",f.when((f.col(\"inuser_old\").isNull())&(f.col(\"address\").isNotNull()),\"Coinbase\").otherwise(f.col(\"inuser_old\")))\n",
    "    df_transactions_general_info_deep = df_transactions_general_info_deep.drop(f.col(\"inuser_old\"))\n",
    "\n",
    "    #Creating unique dataframe with outuser->tx->miduser->tx->inuser\n",
    "    motifs_2 = df_transactions_general_info_deep.groupBy(\"outuser\",\"miduser\",\"inuser\",\"tx_id\",\"tx_id_mid\")\\\n",
    "    .agg(f.count(\"address\"))\\\n",
    "    .select(\"outuser\",\"tx_id\",\"miduser\",\"tx_id_mid\",\"inuser\")\n",
    "\n",
    "    motifs_2 = motifs_2.withColumn(\"loop_mid_out\", f.when(f.col(\"outuser\")==f.col(\"miduser\"),1).otherwise(0))\n",
    "    motifs_2 = motifs_2.withColumn(\"loop_in_mid\", f.when(f.col(\"miduser\")==f.col(\"inuser\"),1).otherwise(0))\n",
    "    motifs_2 = motifs_2.withColumn(\"loop_in_out\", f.when(f.col(\"outuser\")==f.col(\"inuser\"),1).otherwise(0))\n",
    "\n",
    "    motifs_2 = motifs_2.withColumn(\"direct_mid_out\", f.when(f.col(\"outuser\")==f.col(\"miduser\"),0).otherwise(1))\n",
    "    motifs_2 = motifs_2.withColumn(\"direct_in_mid\", f.when(f.col(\"miduser\")==f.col(\"inuser\"),0).otherwise(1))\n",
    "    motifs_2 = motifs_2.withColumn(\"direct_in_out\", f.when(f.col(\"outuser\")==f.col(\"inuser\"),0).otherwise(1))\n",
    "\n",
    "    #Encrich the previous dataframe with information from the motifs-1\n",
    "    for k in range(3,j+1):\n",
    "        motifs_1_part1=sqlContext.read.parquet(path+pathDir+\"/motifs1_\"+str(k)+\".parquet\")\n",
    "        if(k==3):\n",
    "            motifs_1=motifs_1_part1\n",
    "        else:\n",
    "            motifs_1=motifs_1.union(motifs_1_part1)\n",
    "    \n",
    "    motifs_2_cloned = motifs_2.toDF(\"outuser\",\"tx_id\",\"miduser\",\"tx_id_mid\",\"inuser\",\"loop_mid_out\",\"loop_in_mid\",\"loop_in_out\",\"direct_mid_out\",\"direct_in_mid\",\"direct_in_out\")\n",
    "\n",
    "    #Rename correctly the column\n",
    "    motifs_2_cloned= motifs_2_cloned.alias(\"a\").join(motifs_1.alias(\"b\"),(f.col(\"a.outuser\")==f.col(\"b.outuser\"))&(f.col(\"a.miduser\")==f.col(\"b.inuser\"))&(f.col(\"a.tx_id\")==f.col(\"b.tx_id\")),\"leftouter\")\\\n",
    "    .select(\"b.class\",\"a.outuser\",\"a.tx_id\",\"b.address_recv_dist\",\"b.amount_recv\",\"b.fees\",\"b.tx_sent\",\"b.address_sent_dist\",\"b.amount_sent\",\"a.miduser\",\"a.tx_id_mid\",\"a.inuser\",\"a.loop_mid_out\",\"a.loop_in_mid\",\"a.loop_in_out\",\"a.direct_mid_out\",\"a.direct_in_mid\",\"a.direct_in_out\")\\\n",
    "    .withColumnRenamed(\"fees\",\"fee2\")\\\n",
    "    .withColumnRenamed(\"address_recv_dist\",\"address_recv_dist_to_out\")\\\n",
    "    .withColumnRenamed(\"amount_recv\",\"amount_recv_to_out\")\\\n",
    "    .withColumnRenamed(\"tx_sent\",\"tx_sent_from_mid\")\\\n",
    "    .withColumnRenamed(\"address_sent_dist\",\"address_sent_from_mid\")\\\n",
    "    .withColumnRenamed(\"amount_sent\",\"amount_sent_from_mid\").cache()\n",
    "\n",
    "    motifs_2_cloned.count()\n",
    "\n",
    "\n",
    "    motifs_2_cloned= motifs_2_cloned.alias(\"a\").join(motifs_1.alias(\"b\"),(f.col(\"a.inuser\")==f.col(\"b.inuser\"))&(f.col(\"a.miduser\")==f.col(\"b.outuser\"))&(f.col(\"a.tx_id_mid\")==f.col(\"b.tx_id\")),\"leftouter\")\\\n",
    "    .select(\"a.class\",\"a.outuser\",\"a.tx_id\",\"a.address_recv_dist_to_out\",\"a.amount_recv_to_out\",\"a.fee2\",\"a.tx_sent_from_mid\",\"a.address_sent_from_mid\",\"a.amount_sent_from_mid\",\"a.miduser\",\"a.tx_id_mid\",\"b.address_recv_dist\",\"b.amount_recv\",\"b.tx_sent\",\"b.address_sent_dist\",\"b.amount_sent\",\"b.fees\",\"a.inuser\",\"a.loop_mid_out\",\"a.loop_in_mid\",\"a.loop_in_out\",\"a.direct_mid_out\",\"a.direct_in_mid\",\"a.direct_in_out\")\\\n",
    "    .withColumnRenamed(\"fees\",\"fee1\")\\\n",
    "    .withColumnRenamed(\"address_recv_dist\",\"address_recv_to_mid\")\\\n",
    "    .withColumnRenamed(\"amount_recv\",\"amount_recv_to_mid\")\\\n",
    "    .withColumnRenamed(\"tx_sent\",\"tx_sent_from_in\")\\\n",
    "    .withColumnRenamed(\"address_sent_dist\",\"address_sent_from_in\")\\\n",
    "    .withColumnRenamed(\"amount_sent\",\"amount_sent_from_in\")\n",
    "\n",
    "    motifs_2_cloned.count()\n",
    "\n",
    "    #motifs_2_cloned = motifs_2_cloned.alias('a').join(df_label.alias('b'),f.col(\"a.outuser\")==f.col(\"b.label\"),\"leftouter\")\\\n",
    "    #    .select(\"b.class\",\"a.outuser\",\"a.tx_id\",\"a.address_recv_dist_to_out\",\"a.amount_recv_to_out\",\"a.fee2\",\\\n",
    "    #            \"a.tx_sent_from_mid\",\"a.address_sent_from_mid\",\"a.amount_sent_from_mid\",\"a.miduser\",\\\n",
    "    #           \"a.tx_id_mid\",\"a.address_recv_to_mid\",\"a.amount_recv_to_mid\",\"a.tx_sent_from_in\",\"a.address_sent_from_in\",\\\n",
    "    #           \"a.amount_sent_from_in\",\"a.fee1\",\"a.inuser\",\"a.loop_mid_out\",\"a.loop_in_mid\",\"a.loop_in_out\",\\\n",
    "    #           \"a.direct_mid_out\",\"a.direct_in_mid\",\"a.direct_in_out\")\n",
    "\n",
    "    motifs_2_cloned.write.parquet(path+pathDir+\"/motifs2_\"+str(j)+\".parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
