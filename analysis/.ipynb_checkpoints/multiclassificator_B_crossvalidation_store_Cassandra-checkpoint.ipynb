{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.datastax.spark:spark-cassandra-connector_2.11:2.3.0 --conf spark.cassandra.connection.host=localhost pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/opt/spark')\n",
    "from pyspark import SparkContext,SparkConf\n",
    "conf = (SparkConf()\n",
    "         .setMaster(\"spark://10.200.5.39:7077\")\n",
    "         .set(\"spark.driver.host\",\"10.200.5.39\") \n",
    "         .set(\"spark.executor.memory\",\"58g\")\n",
    "         .set('spark.driver.memory', '60G')\n",
    "         .setAppName(\"Classification\"))\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import binascii\n",
    "from pyspark.sql import SQLContext\n",
    "from functools import reduce\n",
    "from sklearn import tree\n",
    "from pyspark.sql.types import *\n",
    "#import pygraphviz\n",
    "import pyspark.sql.functions as f\n",
    "#import networkx as nx\n",
    "#from networkx.readwrite import json_graph\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import AdaBoostClassifier,RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn import datasets,metrics\n",
    "from sklearn.model_selection import StratifiedKFold,KFold,train_test_split\n",
    "import numpy as np\n",
    "import json\n",
    "#import tensorflow as tf\n",
    "from IPython.display import Image\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "#from networkx.drawing.nx_pydot import write_dot\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score  \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report,f1_score,accuracy_score,precision_score,recall_score,matthews_corrcoef\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import pickle\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"hdfs://10.200.5.25:9001/user/titanium/\"\n",
    "\n",
    "cSchema  = StructType([\n",
    "    StructField(\"user\", StringType(), True),\n",
    "    StructField(\"label\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "def join_dataframe_intag(DF,pref):\n",
    "    DF=DF.groupBy(\"user\").agg(f.collect_list(\"label\").alias(\"list\"))\n",
    "    DF = DF.select(\"user\",f.explode(\"list\").alias(\"value\")).groupBy(\"user\",\"value\").agg(f.count(\"value\").alias(\"cnt\"))\n",
    "    DF2 = DF.groupBy(\"user\").agg(f.count(\"user\").alias(\"cnt\")).drop(\"cnt\")\n",
    "    DF2 = DF2.alias(\"a\").join(DF.alias('b'),(f.col(\"a.user\")==f.col(\"b.user\")) & (f.col(\"b.value\")==1),\"leftouter\")\\\n",
    "    .select(\"a.user\",\"b.cnt\").withColumnRenamed(\"cnt\",pref+\"_cnt1\")\n",
    "    DF2 = DF2.alias(\"a\").join(DF.alias('b'),(f.col(\"a.user\")==f.col(\"b.user\")) & (f.col(\"b.value\")==2),\"leftouter\")\\\n",
    "    .select(\"a.user\",pref+\"_cnt1\",\"b.cnt\").withColumnRenamed(\"cnt\",pref+\"_cnt2\")\n",
    "    DF2 = DF2.alias(\"a\").join(DF.alias('b'),(f.col(\"a.user\")==f.col(\"b.user\")) & (f.col(\"b.value\")==3),\"leftouter\")\\\n",
    "    .select(\"a.user\",pref+\"_cnt1\",pref+\"_cnt2\",\"b.cnt\").withColumnRenamed(\"cnt\",pref+\"_cnt3\")\n",
    "    DF2 = DF2.alias(\"a\").join(DF.alias('b'),(f.col(\"a.user\")==f.col(\"b.user\")) & (f.col(\"b.value\")==4),\"leftouter\")\\\n",
    "    .select(\"a.user\",pref+\"_cnt1\",pref+\"_cnt2\",pref+\"_cnt3\",\"b.cnt\").withColumnRenamed(\"cnt\",pref+\"_cnt4\")\n",
    "    DF2 = DF2.alias(\"a\").join(DF.alias('b'),(f.col(\"a.user\")==f.col(\"b.user\")) & (f.col(\"b.value\")==5),\"leftouter\")\\\n",
    "    .select(\"a.user\",pref+\"_cnt1\",pref+\"_cnt2\",pref+\"_cnt3\",pref+\"_cnt4\",\"b.cnt\").withColumnRenamed(\"cnt\",pref+\"_cnt5\")\n",
    "    DF2 = DF2.alias(\"a\").join(DF.alias('b'),(f.col(\"a.user\")==f.col(\"b.user\")) & (f.col(\"b.value\")==6),\"leftouter\")\\\n",
    "    .select(\"a.user\",pref+\"_cnt1\",pref+\"_cnt2\",pref+\"_cnt3\",pref+\"_cnt4\",pref+\"_cnt5\",\"b.cnt\").withColumnRenamed(\"cnt\",pref+\"_cnt6\")\n",
    "    #DF2 = DF2.alias(\"a\").join(DF.alias('b'),(f.col(\"a.user\")==f.col(\"b.user\")) & (f.col(\"b.value\")==7),\"leftouter\")\\\n",
    "    #.select(\"a.user\",pref+\"_cnt1\",pref+\"_cnt2\",pref+\"_cnt3\",pref+\"_cnt4\",pref+\"_cnt5\",pref+\"_cnt6\",\"b.cnt\").withColumnRenamed(\"cnt\",pref+\"_cnt7\")\n",
    "    #DF2 = DF2.alias(\"a\").join(DF.alias('b'),(f.col(\"a.user\")==f.col(\"b.user\")) & (f.col(\"b.value\")==8),\"leftouter\")\\\n",
    "    #.select(\"a.user\",pref+\"_cnt1\",pref+\"_cnt2\",pref+\"_cnt3\",pref+\"_cnt4\",pref+\"_cnt5\",pref+\"_cnt6\",pref+\"_cnt7\",\"b.cnt\").withColumnRenamed(\"cnt\",pref+\"_cnt8\")\n",
    "\n",
    "    DF2=DF2.fillna(0)\n",
    "    return DF2\n",
    "\n",
    "def link_outclass_intag(user,b):\n",
    "    dd = [(str(user[i][0]), int(b[i])) for i in range(len(user))]\n",
    "    df= sqlContext.createDataFrame(sc.parallelize(dd),schema=cSchema)\n",
    "    return df\n",
    "\n",
    "def print_accuracy_report(cl, X, y,n):\n",
    "    acc=np.array([])\n",
    "    f1=np.array([])\n",
    "    prec=np.array([])\n",
    "    rec=np.array([])\n",
    "    mcc=np.array([])\n",
    "    tr=np.array([])\n",
    "    tt=np.array([])\n",
    "    cc=[None]*10\n",
    "    kfold = KFold(n, True, 1)\n",
    "    skf = StratifiedKFold(n, True, 1)\n",
    "    X=np.asarray(X)\n",
    "    y=np.asarray(y)\n",
    "    a=[0]*6\n",
    "    b=[0]*6\n",
    "    c=[0]*6\n",
    "    i=1\n",
    "    j=0\n",
    "    for train, test in skf.split(X,y):\n",
    "        with open(\"/home/titanium/gbc.txt\", \"w\") as f:\n",
    "            f.write(str(i)+\" iteration\")\n",
    "        print(str(i)+\" iteration\")\n",
    "        if(cl==\"RFC\"):\n",
    "            classifier= RandomForestClassifier(n_jobs=2, random_state=0)\n",
    "        elif(cl==\"ADA\"):\n",
    "            classifier = AdaBoostClassifier(n_estimators=50,learning_rate=1)\n",
    "        elif(cl==\"GBC\"):\n",
    "            classifier =GradientBoostingClassifier(learning_rate=0.1, n_estimators=100,max_depth=3, min_samples_split=2, min_samples_leaf=1, subsample=1,max_features='sqrt', random_state=10)\n",
    "\n",
    "        model=classifier.fit(X[train],y[train])\n",
    "        y_pred = model.predict(X[test])\n",
    "        acc=np.append(acc,accuracy_score(y[test], y_pred)*100)\n",
    "        f1=np.append(f1,f1_score(y[test], y_pred,average=\"weighted\"))\n",
    "        prec=np.append(prec,precision_score(y[test], y_pred,average=\"weighted\"))\n",
    "        rec=np.append(rec,recall_score(y[test], y_pred,average=\"weighted\"))\n",
    "        mcc=np.append(mcc,matthews_corrcoef(y[test], y_pred))\n",
    "        tr=np.append(tr,len(train))\n",
    "        tt=np.append(tt,len(test))\n",
    "        cc[i-1]=(classification_report(y[test], y_pred))\n",
    "        i=i+1\n",
    "        n_classes=6\n",
    "        if(cl==\"GBC\"):\n",
    "            y_test=label_binarize(y[test],[1,2,3,4,5,6])\n",
    "            y_score=label_binarize(y_pred,[1,2,3,4,5,6])\n",
    "            fpr = dict()\n",
    "            tpr = dict()\n",
    "            roc_auc = dict()\n",
    "\n",
    "            for h in range(n_classes):\n",
    "                fpr[h], tpr[h], _ = roc_curve(y_test[:, h], y_score[:, h])\n",
    "                roc_auc[h] = auc(fpr[h], tpr[h])\n",
    "            colors = cycle(['blue', 'red', 'green', 'yellow', 'black', 'orange'])\n",
    "            for k, color in zip(range(n_classes), colors):\n",
    "                plt.plot(fpr[k], tpr[k], color=color, lw=lw,\n",
    "                         label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "                         ''.format(k, roc_auc[k]))\n",
    "            plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "            plt.xlim([-0.05, 1.0])\n",
    "            plt.ylim([0.0, 1.05])\n",
    "            plt.xlabel('False Positive Rate')\n",
    "            plt.ylabel('True Positive Rate')\n",
    "            plt.title('Receiver operating characteristic for multi-class data')\n",
    "            plt.legend(loc=\"lower right\")\n",
    "            plt.show()\n",
    "\n",
    "            a[j]= fpr\n",
    "            b[j]= tpr\n",
    "            c[j]= roc_auc\n",
    "            j=j+1\n",
    "\n",
    "    #print(\"train = %s , val = %s\"%(tr.mean(),tt.mean()))\n",
    "    print(\"score = %s , std = %s \"%(acc.mean(),acc.std()))\n",
    "    print(acc)\n",
    "    print(\"f1 = %s\"%(f1.mean()))\n",
    "    print(\"precision = %s\"%(prec.mean()))\n",
    "    print(\"recall = %s\"%(rec.mean()))\n",
    "    print(\"mcc = %s\"%(mcc.mean()))\n",
    "    with open(\"/home/titanium/gbc.txt\", \"w\") as f:\n",
    "        f.write(\"score = %s , std = %s \"%(acc.mean(),acc.std()))\n",
    "    if(cl==\"GBC\"):    \n",
    "        fpr=dict()\n",
    "        for h in range(0,n_classes):\n",
    "            end_a=end_b=end_c=0\n",
    "            for k in range(0,n):\n",
    "                    end_a=end_a+a[k][h][0]\n",
    "                    end_b=end_b+a[k][h][1]\n",
    "                    end_c=end_c+a[k][h][len(a[k][h])-1]\n",
    "            fpr[h]=np.array([end_a/n,end_b/n,end_c/n])\n",
    "\n",
    "        tpr=dict()\n",
    "        for h in range(0,n_classes):\n",
    "            end_a=end_b=end_c=0\n",
    "            for k in range(0,n):\n",
    "                    end_a=end_a+b[k][h][0]\n",
    "                    end_b=end_b+b[k][h][1]\n",
    "                    end_c=end_c+b[k][h][len(b[k][h])-1]\n",
    "            tpr[h]=np.array([end_a/n,end_b/n,end_c/n])\n",
    "\n",
    "        #roc_auc=dict()\n",
    "        for h in range(0,n_classes):\n",
    "            end_a=end_b=end_c=0\n",
    "            for k in range(0,n):\n",
    "                    end_a=end_a+c[k][h]\n",
    "            roc_auc[h]=end_a/n\n",
    "\n",
    "\n",
    "        colors = cycle(['blue', 'red', 'green', 'yellow', 'black', 'orange'])\n",
    "        clc=[\"Exchange\",\"Gambling\",\"Market\",\"Pool\",\"Mixer\",\"Service\"]\n",
    "        for i, color in zip(range(n_classes), colors):\n",
    "            plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "                     label='ROC of {0} (area = {1:0.2f})'\n",
    "                     ''.format(clc[i], roc_auc[i]))\n",
    "        plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "        plt.xlim([-0.05, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver operating characteristic for multi-class data')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.savefig('/home/titanium/ROC_gb.png')\n",
    "        plt.show()\n",
    "\n",
    "    return cc\n",
    "\n",
    "    \n",
    "def store_prediction(filename,df_input,y_pred,name):\n",
    "    DF=link_outclass_intag(df_input,y_pred)    \n",
    "    df = join_dataframe_intag(DF,name)\n",
    "    df.write.parquet(path+\"analysis/prediction/\"+filename+\".parquet\")\n",
    "    \n",
    "def testing(classifier, X_train, y_train,X_test,y_test,name):\n",
    "    filename= '/home/titanium/spark_ml/'+name+\".pkl\"\n",
    "    model=classifier.fit(X_train,y_train)\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "    print(\"end fit...start predict\")\n",
    "    y_pred = model.predict(X_test)    \n",
    "    print(\"train = %s , test = %s\"%(len(X_train),len(X_test)))\n",
    "    print(\"score = %s\" % (accuracy_score(y_test, y_pred)*100))\n",
    "    print(matthews_corrcoef(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    return y_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_all(cc,n):\n",
    "    split=[None]*n\n",
    "    split_final=[None]*n\n",
    "    for i in range(n):\n",
    "        split[i]=cc[i].split(\" \")\n",
    "        split_final[i]=[1]\n",
    "        for idx in range(len(split[i])):\n",
    "            if(split[i][idx]!=\"\"):\n",
    "                split_final[i].append(split[i][idx])\n",
    "    p1=p2=p3=p4=p5=p6=0.0\n",
    "    r1=r2=r3=r4=r5=r6=0.0\n",
    "    f1=f2=f3=f4=f5=f6=0.0\n",
    "    for i in range(n):\n",
    "        p1=p1+float(split_final[i][6])\n",
    "        p2=p2+float(split_final[i][11])\n",
    "        p3=p3+float(split_final[i][16])\n",
    "        p4=p4+float(split_final[i][21])\n",
    "        p5=p5+float(split_final[i][26])\n",
    "        p6=p6+float(split_final[i][31])\n",
    "\n",
    "        r1=r1+float(split_final[i][7])\n",
    "        r2=r2+float(split_final[i][12])\n",
    "        r3=r3+float(split_final[i][17])\n",
    "        r4=r4+float(split_final[i][22])\n",
    "        r5=r5+float(split_final[i][27])\n",
    "        r6=r6+float(split_final[i][32])\n",
    "\n",
    "        f1=f1+float(split_final[i][8])\n",
    "        f2=f2+float(split_final[i][13])\n",
    "        f3=f3+float(split_final[i][18])\n",
    "        f4=f4+float(split_final[i][23])\n",
    "        f5=f5+float(split_final[i][28])\n",
    "        f6=f6+float(split_final[i][33])\n",
    "\n",
    "    print(\"p1=\"+str(p1/n))\n",
    "    print(\"p2=\"+str(p2/n))\n",
    "    print(\"p3=\"+str(p3/n))\n",
    "    print(\"p4=\"+str(p4/n))\n",
    "    print(\"p5=\"+str(p5/n))\n",
    "    print(\"p6=\"+str(p6/n))\n",
    "\n",
    "    print(\"r1=\"+str(r1/n))\n",
    "    print(\"r2=\"+str(r2/n))\n",
    "    print(\"r3=\"+str(r3/n))\n",
    "    print(\"r4=\"+str(r4/n))\n",
    "    print(\"r5=\"+str(r5/n))\n",
    "    print(\"r6=\"+str(r6/n))\n",
    "\n",
    "    print(\"f1=\"+str(f1/n))\n",
    "    print(\"f2=\"+str(f2/n))\n",
    "    print(\"f3=\"+str(f3/n))\n",
    "    print(\"f4=\"+str(f4/n))\n",
    "    print(\"f5=\"+str(f5/n))\n",
    "    print(\"f6=\"+str(f6/n))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Definition\n",
    "# 1: exchange\n",
    "# 2: gambling\n",
    "# 3: market\n",
    "# 4: pool\n",
    "# 5: mixer\n",
    "# 6: service\n",
    "# 7: wallet\n",
    "# 8: lending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "#               IMPORT DATAFRAMES\n",
    "#########################################################################\n",
    "path = \"hdfs://10.200.5.25:9001/user/titanium/\"\n",
    "path_directory=\"analysis/\"\n",
    "entity= sqlContext.read.parquet(path+path_directory+\"complete_entity.parquet\")\n",
    "address= sqlContext.read.parquet(path+path_directory+\"complete_address.parquet\")\n",
    "motif1 = sqlContext.read.parquet(path+path_directory+\"complete_motifs1.parquet\")\n",
    "motif2 = sqlContext.read.parquet(path+path_directory+\"complete_motifs2.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_=\"walletexp_data/list.csv\"\n",
    "df_list= sqlContext.read.format(\"csv\")\\\n",
    "         .option(\"header\", \"true\")\\\n",
    "         .load(path+list_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = df_list.withColumn(\"label\",f.when(f.col(\"class\")==\"exchange\",1).otherwise(0))\n",
    "df_list = df_list.withColumn(\"label\",f.when(f.col(\"class\")==\"gambling\",2).otherwise(f.col(\"label\")))\n",
    "df_list = df_list.withColumn(\"label\",f.when(f.col(\"class\")==\"market\",3).otherwise(f.col(\"label\")))\n",
    "df_list = df_list.withColumn(\"label\",f.when(f.col(\"class\")==\"pool\",4).otherwise(f.col(\"label\")))\n",
    "df_list = df_list.withColumn(\"label\",f.when(f.col(\"class\")==\"mixer\",5).otherwise(f.col(\"label\")))\n",
    "df_list = df_list.withColumn(\"label\",f.when(f.col(\"class\")==\"service\",6).otherwise(f.col(\"label\")))\n",
    "#df_list = df_list.withColumn(\"label\",f.when(f.col(\"class\")==\"wallet\",7).otherwise(f.col(\"label\")))\n",
    "#df_list = df_list.withColumn(\"label\",f.when(f.col(\"class\")==\"lending\",8).otherwise(f.col(\"label\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list=df_list.where(f.col(\"label\")>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motif2.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store DF into Cassandra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity=entity.withColumnRenamed(\"count_recv\",\"tx_recv\")\n",
    "entity=entity.withColumnRenamed(\"count_sent\",\"tx_sent\")\n",
    "entity=entity.withColumnRenamed(\"balancerecv\",\"amount_recv\")\n",
    "entity=entity.withColumnRenamed(\"balancesend\",\"amount_sent\")\n",
    "entity.write\\\n",
    ".format(\"org.apache.spark.sql.cassandra\")\\\n",
    ".mode('append')\\\n",
    ".options(table=\"entity\", keyspace=\"kryptosare\")\\\n",
    ".save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address=address.withColumnRenamed(\"count_rec\",\"tx_recv\")\n",
    "address=address.withColumnRenamed(\"count_sent\",\"tx_sent\")\n",
    "address=address.withColumnRenamed(\"totamount_rec\",\"amount_recv\")\n",
    "address=address.withColumnRenamed(\"totamount_sent\",\"amount_sent\")\n",
    "address.write\\\n",
    ".format(\"org.apache.spark.sql.cassandra\")\\\n",
    ".mode('append')\\\n",
    ".options(table=\"address\", keyspace=\"kryptosare\")\\\n",
    ".save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "#               ENTITY ML\n",
    "####################################################################\n",
    "\n",
    "entity_feature = entity.where(f.col(\"label\")<7)\n",
    "\n",
    "ent_X=entity_feature.select(\"balancerecv\",\"balancesend\",\"balance\",\"count_recv\",\"count_sent\",\"add_recv\",\"add_sent\")\n",
    "ent_y=entity_feature.select(\"label\")\n",
    "\n",
    "#Round amount field\n",
    "ent_X = ent_X.withColumn(\"balancerecv\", f.round(ent_X[\"balancerecv\"], 6))\n",
    "ent_X = ent_X.withColumn(\"balancesend\", f.round(ent_X[\"balancesend\"], 6))\n",
    "ent_X = ent_X.withColumn(\"balance\", f.round(ent_X[\"balance\"], 6))\n",
    "\n",
    "#Transform input/output dataframe in vector\n",
    "X_train_ent= ent_X.collect()\n",
    "y_train_ent = ent_y.collect()\n",
    "\n",
    "#Reshape the output vector\n",
    "y_train_ent=np.reshape(y_train_ent,(len(y_train_ent),))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#abc_ent = AdaBoostClassifier(n_estimators=50,learning_rate=1)\n",
    "cc=print_accuracy_report(\"ADA\", X_train_ent, y_train_ent,5)\n",
    "print(\"#####################################################\")\n",
    "#y_pred=testing(abc_ent, X_train_ent, y_train_ent,X_test_ent,y_test_ent,\"ada_ent\")\n",
    "#store_prediction(\"y_pred_ada_ent\",ent_X_test,y_pred,\"ent\")\n",
    "average_all(cc,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rfc_ent= RandomForestClassifier(n_jobs=2, random_state=0)\n",
    "cc=print_accuracy_report(\"RFC\", X_train_ent, y_train_ent,5)\n",
    "print(\"#####################################################\")\n",
    "#y_pred=testing(rfc_ent, X_train_ent, y_train_ent,X_test_ent,y_test_ent,\"rfc_ent\")\n",
    "#store_prediction(\"y_pred_rfc_ent\",ent_X_test,y_pred,\"ent\")\n",
    "average_all(cc,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc=print_accuracy_report(\"GBC\", X_train_ent, y_train_ent,5)\n",
    "average_all(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "#               ADDRESS ML\n",
    "####################################################################\n",
    "\n",
    "address_feature = address.fillna(0)\n",
    "#address_feature = address_d1.where(f.col(\"label\")<6)\n",
    "\n",
    "#Transform label to class index \n",
    "#address_feature=transform_label_to_id(address_data1,\"label\",\"user\")\n",
    "address_split=address_feature.randomSplit([0.7,0.3])\n",
    "#Split the input and the output from dataframe \n",
    "add_X=address_split[0].select(\"count_rec\",\"totamount_rec\",\"count_sent\",\"totamount_sent\",\"balance\",\"unique\",\"sibling\")\n",
    "add_y=address_split[0].select(\"label\")\n",
    "#Round amount field\n",
    "add_X = add_X.withColumn(\"totamount_rec\", f.round(add_X[\"totamount_rec\"], 6))\n",
    "add_X = add_X.withColumn(\"totamount_sent\", f.round(add_X[\"totamount_sent\"], 6))\n",
    "add_X = add_X.withColumn(\"balance\", f.round(add_X[\"balance\"], 6))\n",
    "\n",
    "#Transform input/output dataframe in vector\n",
    "X_train_add = add_X.collect()\n",
    "y_train_add = add_y.collect()\n",
    "\n",
    "#Reshape the output vector\n",
    "y_train_add=np.reshape(y_train_add,(len(y_train_add),))\n",
    "\n",
    "add_X_test=address_split[1].select(\"user\",\"count_rec\",\"totamount_rec\",\"count_sent\",\"totamount_sent\",\"balance\",\"unique\",\"sibling\")\n",
    "add_y=address_split[1].select(\"label\")\n",
    "#Round amount field\n",
    "add_X_test = add_X_test.withColumn(\"totamount_rec\", f.round(add_X_test[\"totamount_rec\"], 6))\n",
    "add_X_test = add_X_test.withColumn(\"totamount_sent\", f.round(add_X_test[\"totamount_sent\"], 6))\n",
    "add_X_test = add_X_test.withColumn(\"balance\", f.round(add_X_test[\"balance\"], 6))\n",
    "\n",
    "add_X=add_X_test.select(\"count_rec\",\"totamount_rec\",\"count_sent\",\"totamount_sent\",\"balance\",\"unique\",\"sibling\")\n",
    "\n",
    "add_X_test=add_X_test.select(\"user\").collect()\n",
    "#Transform input/output dataframe in vector\n",
    "X_test_add = add_X.collect()\n",
    "y_test_add = add_y.collect()\n",
    "\n",
    "#Reshape the output vector\n",
    "y_test_add=np.reshape(y_test_add,(len(y_test_add),))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gbc classifier\n",
    "cc=print_accuracy_report(\"GBC\", X_train_add, y_train_add,5)\n",
    "print(\"#####################################################\")\n",
    "classifier =GradientBoostingClassifier()\n",
    "pred=testing(classifier, X_train_add, y_train_add,X_test_add,y_test_add,\"gbc_add\")\n",
    "store_prediction(\"y_pred_gbc_add\",add_X_test,pred,\"add\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adaboost classifier\n",
    "cc=print_accuracy_report(\"ADA\", X_train_add, y_train_add,5)\n",
    "print(\"#####################################################\")\n",
    "classifier= AdaBoostClassifier(n_estimators=50,learning_rate=1)\n",
    "pred=testing(classifier, X_train_add, y_train_add,X_test_add,y_test_add,\"ada_add\")\n",
    "store_prediction(\"y_pred_ada_add\",add_X_test,pred,\"add\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomforest classifier\n",
    "cc=print_accuracy_report(\"RFC\", X_train_add, y_train_add,5)\n",
    "print(\"#####################################################\")\n",
    "#classifier = RandomForestClassifier(n_jobs=2, random_state=0)\n",
    "#pred=testing(classifier, X_train_add, y_train_add,X_test_add,y_test_add,\"rf_add\")\n",
    "#store_prediction(\"y_pred_rfc_add\",add_X_test,pred,\"add\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format motifs amount data (round and cluster to reduce the amount of data)\n",
    "\n",
    "motif11=motif1.withColumn(\"amount_recv\",(f.round(f.col(\"amount_recv\")/100000)*100000))\n",
    "motif11=motif11.withColumn(\"amount_sent\",(f.round(f.col(\"amount_sent\")/100000)*100000))\n",
    "motif11=motif11.withColumn(\"fees\",(f.round(f.col(\"fees\")/100)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "motif11=motif11.groupby(\"outuser\",\"address_recv_dist\",\"address_sent_dist\",\"amount_recv\",\"tx_sent\",\"amount_sent\",\"tx_recv_tot\",\"fees\",\"loop_in_out\",\"direct_in_out\")\\\n",
    ".agg(f.first(\"label\").alias(\"label\"),f.count(\"label\").alias(\"repetition\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "#               MOTIFS-1 ML\n",
    "####################################################################\n",
    "df_motifs1_train_test=motif11.randomSplit([0.7,0.3])\n",
    "\n",
    "df_motifs1=df_motifs1_train_test[0].randomSplit([0.2,0.2,0.2,0.2,0.2])\n",
    "\n",
    "\n",
    "X_train_mot1=[]\n",
    "y_train_mot1=[]\n",
    "\n",
    "for i in range(0,5):\n",
    "    #Split the input and the output from dataframe \n",
    "    mot1_X=df_motifs1[i].select(\"address_recv_dist\",\"amount_recv\",\"tx_sent\",\"address_sent_dist\",\"amount_sent\",\"tx_recv_tot\",\"fees\",\"loop_in_out\",\"direct_in_out\",\"repetition\")\n",
    "    mot1_y=df_motifs1[i].select(\"label\")\n",
    "\n",
    "    #Round amount field\n",
    "    mot1_X = mot1_X.withColumn(\"amount_recv\", f.round(mot1_X[\"amount_recv\"], 6))\n",
    "    mot1_X = mot1_X.withColumn(\"amount_sent\", f.round(mot1_X[\"amount_sent\"], 6))\n",
    "    mot1_X = mot1_X.withColumn(\"fees\", f.round(mot1_X[\"fees\"], 6))\n",
    "\n",
    "    #Transform input/output dataframe in vector\n",
    "    X_train_mot1_ = mot1_X.collect()\n",
    "    y_train_mot1_ = mot1_y.collect()\n",
    "    X_train_mot1 = X_train_mot1+X_train_mot1_\n",
    "    y_train_mot1 = y_train_mot1+y_train_mot1_\n",
    "\n",
    "#Reshape the output vector\n",
    "y_train_mot1=np.reshape(y_train_mot1,(len(y_train_mot1),))\n",
    "\n",
    "#Store training 1-motifs\n",
    "np.save('/home/titanium/motifs_collection/X_train_mot1.npy', X_train_mot1)\n",
    "np.save('/home/titanium/motifs_collection/y_train_mot1.npy', y_train_mot1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_motifs1=df_motifs1_train_test[1].randomSplit([0.2,0.2,0.2,0.2,0.2])\n",
    "\n",
    "X_test_mot1=[]\n",
    "X_test_mot1_withuser=[]\n",
    "y_test_mot1=[]\n",
    "\n",
    "for i in range(0,5):\n",
    "    #Split the input and the output from dataframe \n",
    "    mot1_X=df_motifs1[i].select(\"outuser\",\"address_recv_dist\",\"amount_recv\",\"tx_sent\",\"address_sent_dist\",\"amount_sent\",\"tx_recv_tot\",\"fees\",\"loop_in_out\",\"direct_in_out\",\"repetition\")\n",
    "    mot1_y=df_motifs1[i].select(\"label\")\n",
    "\n",
    "    #Round amount field\n",
    "    mot1_X = mot1_X.withColumn(\"amount_recv\", f.round(mot1_X[\"amount_recv\"], 6))\n",
    "    mot1_X = mot1_X.withColumn(\"amount_sent\", f.round(mot1_X[\"amount_sent\"], 6))\n",
    "    mot1_X = mot1_X.withColumn(\"fees\", f.round(mot1_X[\"fees\"], 6))\n",
    "    \n",
    "    X_test_mot1_wu = mot1_X.select(\"outuser\").collect()\n",
    "    X_test_mot1_ = mot1_X.select(\"address_recv_dist\",\"amount_recv\",\"tx_sent\",\"address_sent_dist\",\"amount_sent\",\"tx_recv_tot\",\"fees\",\"loop_in_out\",\"direct_in_out\",\"repetition\")\\\n",
    "    .collect()\n",
    "    y_test_mot1_ = mot1_y.collect()\n",
    "    \n",
    "    X_test_mot1_withuser=X_test_mot1_withuser+X_test_mot1_wu\n",
    "    X_test_mot1 = X_test_mot1+X_test_mot1_\n",
    "    y_test_mot1 = y_test_mot1+y_test_mot1_\n",
    "\n",
    "#Reshape the output vector\n",
    "y_test_mot1=np.reshape(y_test_mot1,(len(y_test_mot1),))\n",
    "\n",
    "#Store testing 1-motifs\n",
    "np.save('/home/titanium/motifs_collection/X_test_mot1.npy', X_test_mot1)\n",
    "np.save('/home/titanium/motifs_collection/y_test_mot1.npy', y_test_mot1)\n",
    "np.save('/home/titanium/motifs_collection/X_test_mot1_withuser.npy', X_test_mot1_withuser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reload the 1-motifs data split into train and test X and y\n",
    "X_train_mot1=np.load('/home/titanium/motifs_collection/X_train_mot1.npy')\n",
    "y_train_mot1=np.load('/home/titanium/motifs_collection/y_train_mot1.npy')\n",
    "\n",
    "X_test_mot1=np.load('/home/titanium/motifs_collection/X_test_mot1.npy')\n",
    "X_test_mot1_withuser=np.load('/home/titanium/motifs_collection/X_test_mot1_withuser.npy')\n",
    "y_test_mot1=np.load('/home/titanium/motifs_collection/y_test_mot1.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaboost Classifier\n",
    "cc=print_accuracy_report(\"ADA\", X_train_mot1, y_train_mot1,5)\n",
    "print(\"#####################################################\")\n",
    "classifier= AdaBoostClassifier(n_estimators=50,learning_rate=1)\n",
    "y_pred=testing(classifier, X_train_mot1, y_train_mot1,X_test_mot1,y_test_mot1,\"ada_mot1\")\n",
    "store_prediction(\"y_pred_ada_mot1\",X_test_mot1_withuser,y_pred,\"mot1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest Classifier\n",
    "cc=print_accuracy_report(\"RFC\", X_train_mot1, y_train_mot1,5)\n",
    "print(\"#####################################################\")\n",
    "classifier = RandomForestClassifier(n_jobs=2, random_state=0)\n",
    "y_pred=testing(classifier, X_train_mot1, y_train_mot1,X_test_mot1,y_test_mot1,\"rfc_mot1\")\n",
    "store_prediction(\"y_pred_rfc_mot1\",X_test_mot1_withuser,y_pred,\"mot1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBC Classifier\n",
    "cc=print_accuracy_report(\"GBC\", X_train_mot1, y_train_mot1,5)\n",
    "print(\"#####################################################\")\n",
    "#classifier =GradientBoostingClassifier()\n",
    "#y_pred=testing(classifier, X_train_mot1, y_train_mot1,X_test_mot1,y_test_mot1,\"gbc_mot1\")\n",
    "#store_prediction(\"y_pred_gbc_mot1\",X_test_mot1_withuser,y_pred,\"mot1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format motifs amount data (round and cluster to reduce the amount of data)\n",
    "\n",
    "motif2=motif2.fillna(0,subset=[\"amount_sent_from_in\",\"fee1\"])\n",
    "motif21=motif2.withColumn(\"amount_recv_to_out\",(f.round(f.col(\"amount_recv_to_out\")/1000000)*1000000))\n",
    "motif21=motif21.withColumn(\"amount_sent_from_mid\",(f.round(f.col(\"amount_sent_from_mid\")/1000000)*1000000))\n",
    "motif21=motif21.withColumn(\"amount_recv_to_mid\",(f.round(f.col(\"amount_recv_to_mid\")/1000000)*1000000))\n",
    "motif21=motif21.withColumn(\"amount_sent_from_in\",(f.round(f.col(\"amount_sent_from_in\")/1000000)*1000000))\n",
    "\n",
    "motif21=motif21.withColumn(\"fee2\",(f.round(f.col(\"fee2\")/1000)*1000))\n",
    "motif21=motif21.withColumn(\"fee1\",(f.round(f.col(\"fee1\")/1000)*1000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "motif21=motif21.groupby(\"outuser\",\"address_recv_dist_to_out\",\"amount_recv_to_out\",\"fee2\",\\\n",
    "                             \"tx_sent_from_mid\",\"address_sent_from_mid\",\"amount_sent_from_mid\",\\\n",
    "                             \"address_recv_to_mid\",\"amount_recv_to_mid\",\"tx_sent_from_in\",\"address_sent_from_in\",\\\n",
    "                             \"amount_sent_from_in\",\"fee1\",\"loop_mid_out\",\"loop_in_mid\",\"loop_in_out\",\\\n",
    "                             \"direct_mid_out\",\"direct_in_mid\",\"direct_in_out\")\\\n",
    ".agg(f.first(\"label\").alias(\"label\"),f.count(\"label\").alias(\"repetition\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the dataframe into two part \n",
    "df_motif2_train_test=motif21.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the dataframe separeted into train and test\n",
    "df_motif2_train_test[0].write.parquet(path+\"analysis/complete_motifs2_train.parquet\")\n",
    "df_motif2_train_test[1].write.parquet(path+\"analysis/complete_motifs2_test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the 2-motifs test and train\n",
    "df_motif2_train= sqlContext.read.parquet(path+\"analysis/complete_motifs2_train.parquet\")\n",
    "df_motif2_test= sqlContext.read.parquet(path+\"analysis/complete_motifs2_test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "#               MOTIFS-2 ML\n",
    "####################################################################\n",
    "\n",
    "df_motifs2=df_motif2_train.randomSplit([0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1])\n",
    "\n",
    "X_train_mot2=[]\n",
    "y_train_mot2=[]\n",
    "\n",
    "for i in range(0,10):\n",
    "    #Split the input and the output from dataframe \n",
    "    mot2_X=df_motifs2[i].select(\"address_recv_dist_to_out\",\"amount_recv_to_out\",\"fee2\",\\\n",
    "                             \"tx_sent_from_mid\",\"address_sent_from_mid\",\"amount_sent_from_mid\",\\\n",
    "                             \"address_recv_to_mid\",\"amount_recv_to_mid\",\"tx_sent_from_in\",\"address_sent_from_in\",\\\n",
    "                             \"amount_sent_from_in\",\"fee1\",\"loop_mid_out\",\"loop_in_mid\",\"loop_in_out\",\\\n",
    "                             \"direct_mid_out\",\"direct_in_mid\",\"direct_in_out\",\"repetition\")\n",
    "\n",
    "    mot2_y=df_motifs2[i].select(\"label\")\n",
    "\n",
    "    #Round amount field\n",
    "    mot2_X = mot2_X.withColumn(\"amount_recv_to_out\", f.round(mot2_X[\"amount_recv_to_out\"], 6))\n",
    "    mot2_X = mot2_X.withColumn(\"amount_sent_from_mid\", f.round(mot2_X[\"amount_sent_from_mid\"], 6))\n",
    "    mot2_X = mot2_X.withColumn(\"amount_recv_to_mid\", f.round(mot2_X[\"amount_recv_to_mid\"], 6))\n",
    "    mot2_X = mot2_X.withColumn(\"amount_sent_from_in\", f.round(mot2_X[\"amount_sent_from_in\"], 6))\n",
    "    mot2_X = mot2_X.withColumn(\"fee2\", f.round(mot2_X[\"fee2\"], 6))\n",
    "    mot2_X = mot2_X.withColumn(\"fee1\", f.round(mot2_X[\"fee1\"], 6))\n",
    "\n",
    "    #Transform input/output dataframe in vector\n",
    "    X_train_mot2_ = mot2_X.collect()\n",
    "    y_train_mot2_ = mot2_y.collect()\n",
    "    \n",
    "    X_train_mot2 = X_train_mot2+X_train_mot2_\n",
    "    y_train_mot2 = y_train_mot2+y_train_mot2_\n",
    "#Reshape the output vector\n",
    "y_train_mot2=np.reshape(y_train_mot2,(len(y_train_mot2),))\n",
    "\n",
    "#Store the train X and y\n",
    "np.save('/home/titanium/motifs_collection/X_train_mot2.npy', X_train_mot2)\n",
    "np.save('/home/titanium/motifs_collection/y_train_mot2.npy', y_train_mot2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_motifs2=df_motif2_test.randomSplit([0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1])\n",
    "\n",
    "X_test_mot2_withuser=[]\n",
    "X_test_mot2=[]\n",
    "y_test_mot2=[]\n",
    "\n",
    "for i in range(0,10):\n",
    "    #Split the input and the output from dataframe \n",
    "    mot2_X=df_motifs2[i].select(\"outuser\",\"address_recv_dist_to_out\",\"amount_recv_to_out\",\"fee2\",\\\n",
    "                             \"tx_sent_from_mid\",\"address_sent_from_mid\",\"amount_sent_from_mid\",\\\n",
    "                             \"address_recv_to_mid\",\"amount_recv_to_mid\",\"tx_sent_from_in\",\"address_sent_from_in\",\\\n",
    "                             \"amount_sent_from_in\",\"fee1\",\"loop_mid_out\",\"loop_in_mid\",\"loop_in_out\",\\\n",
    "                             \"direct_mid_out\",\"direct_in_mid\",\"direct_in_out\",\"repetition\")\n",
    "\n",
    "    mot2_y=df_motifs2[i].select(\"label\")\n",
    "\n",
    "    #Round amount field\n",
    "    mot2_X = mot2_X.withColumn(\"amount_recv_to_out\", f.round(mot2_X[\"amount_recv_to_out\"], 6))\n",
    "    mot2_X = mot2_X.withColumn(\"amount_sent_from_mid\", f.round(mot2_X[\"amount_sent_from_mid\"], 6))\n",
    "    mot2_X = mot2_X.withColumn(\"amount_recv_to_mid\", f.round(mot2_X[\"amount_recv_to_mid\"], 6))\n",
    "    mot2_X = mot2_X.withColumn(\"amount_sent_from_in\", f.round(mot2_X[\"amount_sent_from_in\"], 6))\n",
    "    mot2_X = mot2_X.withColumn(\"fee2\", f.round(mot2_X[\"fee2\"], 6))\n",
    "    mot2_X = mot2_X.withColumn(\"fee1\", f.round(mot2_X[\"fee1\"], 6))\n",
    "\n",
    "    #Transform input/output dataframe in vector\n",
    "    X_test_mot2_wu = mot2_X.select(\"outuser\").collect()\n",
    "    X_test_mot2_ = mot2_X.select(\"address_recv_dist_to_out\",\"amount_recv_to_out\",\"fee2\",\\\n",
    "                             \"tx_sent_from_mid\",\"address_sent_from_mid\",\"amount_sent_from_mid\",\\\n",
    "                             \"address_recv_to_mid\",\"amount_recv_to_mid\",\"tx_sent_from_in\",\"address_sent_from_in\",\\\n",
    "                             \"amount_sent_from_in\",\"fee1\",\"loop_mid_out\",\"loop_in_mid\",\"loop_in_out\",\\\n",
    "                             \"direct_mid_out\",\"direct_in_mid\",\"direct_in_out\",\"repetition\").collect()\n",
    "    \n",
    "    y_test_mot2_ = mot2_y.collect()\n",
    "    \n",
    "    X_test_mot2_withuser=X_test_mot2_withuser+X_test_mot2_wu\n",
    "    X_test_mot2 = X_test_mot2+X_test_mot2_\n",
    "    y_test_mot2 = y_test_mot2+y_test_mot2_\n",
    "#Reshape the output vector\n",
    "y_test_mot2=np.reshape(y_test_mot2,(len(y_test_mot2),))\n",
    "\n",
    "#Store the testing X and y\n",
    "np.save('/home/titanium/motifs_collection/X_test_mot2.npy', X_test_mot2)\n",
    "np.save('/home/titanium/motifs_collection/y_test_mot2.npy', y_test_mot2)\n",
    "np.save('/home/titanium/motifs_collection/X_test_mot2_withuser.npy', X_test_mot2_withuser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the train and test data\n",
    "X_train_mot2=np.load('/home/titanium/motifs_collection/X_train_mot2.npy')\n",
    "y_train_mot2=np.load('/home/titanium/motifs_collection/y_train_mot2.npy')\n",
    "\n",
    "X_test_mot2=np.load('/home/titanium/motifs_collection/X_test_mot2.npy')\n",
    "X_test_mot2_withuser=np.load('/home/titanium/motifs_collection/X_test_mot2_withuser.npy')\n",
    "y_test_mot2=np.load('/home/titanium/motifs_collection/y_test_mot2.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaboost Classifier\n",
    "cc=print_accuracy_report(\"ADA\", X_train_mot2, y_train_mot2,5)\n",
    "print(\"#####################################################\")\n",
    "classifier= AdaBoostClassifier(n_estimators=50,learning_rate=1)\n",
    "y_pred=testing(classifier, X_train_mot2, y_train_mot2,X_test_mot2,y_test_mot2,\"ada_mot2\")\n",
    "store_prediction(\"y_pred_ada_mot2\",X_test_mot2_withuser,y_pred,\"mot2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifier\n",
    "cc=print_accuracy_report(\"RFC\", X_train_mot2, y_train_mot2,5)\n",
    "print(\"#####################################################\")\n",
    "classifier = RandomForestClassifier(n_jobs=2, random_state=0)\n",
    "y_pred=testing(classifier, X_train_mot2, y_train_mot2,X_test_mot2,y_test_mot2,\"rfc_mot2\")\n",
    "store_prediction(\"y_pred_rfc_mot2\",X_test_mot2_withuser,y_pred,\"mot2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBC Classifier\n",
    "cc=print_accuracy_report(\"GBC\", X_train_mot2, y_train_mot2,5)\n",
    "print(\"#####################################################\")\n",
    "#classifier =GradientBoostingClassifier()\n",
    "#y_pred=testing(classifier, X_train_mot2, y_train_mot2,X_test_mot2,y_test_mot2,\"gbc_mot2\")\n",
    "#store_prediction(\"y_pred_gbc_mot2\",X_test_mot2_withuser,y_pred,\"mot2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cascading final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"hdfs://10.200.5.25:9001/user/titanium/\"\n",
    "path_directory=\"analysis/\"\n",
    "entity= sqlContext.read.parquet(path+path_directory+\"complete_entity.parquet\")\n",
    "path_directory=\"analysis/prediction/\"\n",
    "\n",
    "#Load data from prediction\n",
    "y_pred_ada_add= sqlContext.read.parquet(path+path_directory+\"y_pred_ada_add.parquet\")\n",
    "y_pred_ada_mot1= sqlContext.read.parquet(path+path_directory+\"y_pred_ada_mot1.parquet\")\n",
    "y_pred_ada_mot2= sqlContext.read.parquet(path+path_directory+\"y_pred_ada_mot2.parquet\")\n",
    "y_pred_rfc_add= sqlContext.read.parquet(path+path_directory+\"y_pred_rfc_add.parquet\")\n",
    "y_pred_rfc_mot1= sqlContext.read.parquet(path+path_directory+\"y_pred_rfc_mot1.parquet\")\n",
    "y_pred_rfc_mot2= sqlContext.read.parquet(path+path_directory+\"y_pred_rfc_mot2.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize the information of the prediction in each dataframe\n",
    "col=[\"add_cnt1\",\"add_cnt2\",\"add_cnt3\",\"add_cnt4\",\"add_cnt5\",\"add_cnt6\"]\n",
    "y_pred_ada_add = y_pred_ada_add.withColumn(\"sum\",sum([y_pred_ada_add[c] for c in col]))\n",
    "for c in col:\n",
    "    y_pred_ada_add = y_pred_ada_add.withColumn(c,f.round(f.col(c)/f.col(\"sum\")*100,2))\n",
    "    \n",
    "y_pred_rfc_add = y_pred_rfc_add.withColumn(\"sum\",sum([y_pred_rfc_add[c] for c in col]))\n",
    "for c in col:\n",
    "    y_pred_rfc_add = y_pred_rfc_add.withColumn(c,f.round(f.col(c)/f.col(\"sum\")*100,2))\n",
    "       \n",
    "########################################### \n",
    "col=[\"mot1_cnt1\",\"mot1_cnt2\",\"mot1_cnt3\",\"mot1_cnt4\",\"mot1_cnt5\",\"mot1_cnt6\"]\n",
    "y_pred_ada_mot1 = y_pred_ada_mot1.withColumn(\"sum\",sum([y_pred_ada_mot1[c] for c in col]))\n",
    "for c in col:\n",
    "    y_pred_ada_mot1 = y_pred_ada_mot1.withColumn(c,f.round(f.col(c)/f.col(\"sum\")*100,2))\n",
    "    \n",
    "y_pred_rfc_mot1 = y_pred_rfc_mot1.withColumn(\"sum\",sum([y_pred_rfc_mot1[c] for c in col]))\n",
    "for c in col:\n",
    "    y_pred_rfc_mot1 = y_pred_rfc_mot1.withColumn(c,f.round(f.col(c)/f.col(\"sum\")*100,2))\n",
    "    \n",
    "###########################################   \n",
    "col=[\"mot2_cnt1\",\"mot2_cnt2\",\"mot2_cnt3\",\"mot2_cnt4\",\"mot2_cnt5\",\"mot2_cnt6\"]\n",
    "y_pred_ada_mot2 = y_pred_ada_mot2.withColumn(\"sum\",sum([y_pred_ada_mot2[c] for c in col]))\n",
    "for c in col:\n",
    "    y_pred_ada_mot2 = y_pred_ada_mot2.withColumn(c,f.round(f.col(c)/f.col(\"sum\")*100,2))\n",
    "y_pred_rfc_mot2 = y_pred_rfc_mot2.withColumn(\"sum\",sum([y_pred_rfc_mot2[c] for c in col]))\n",
    "for c in col:\n",
    "    y_pred_rfc_mot2 = y_pred_rfc_mot2.withColumn(c,f.round(f.col(c)/f.col(\"sum\")*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove a \"sum\" column\n",
    "y_pred_ada_add =y_pred_ada_add.drop(\"sum\")\n",
    "y_pred_rfc_add=y_pred_rfc_add.drop(\"sum\")\n",
    "y_pred_ada_mot1=y_pred_ada_mot1.drop(\"sum\")\n",
    "y_pred_ada_mot2=y_pred_ada_mot2.drop(\"sum\")\n",
    "y_pred_rfc_mot1=y_pred_rfc_mot1.drop(\"sum\")\n",
    "y_pred_rfc_mot2=y_pred_rfc_mot2.drop(\"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join all the dataframe information into one\n",
    "df_final_rf = entity.join(y_pred_rfc_add,['user'],\"outer\")\n",
    "df_final_rf = df_final_rf.join(y_pred_rfc_mot1,['user'],\"outer\")\n",
    "df_final_rf = df_final_rf.join(y_pred_rfc_mot2,['user'],\"outer\")\n",
    "df_final_rf = df_final_rf.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create final dataframe, split into X and y and convert them into list\n",
    "rf_final_X=df_final_rf.select(\"balancerecv\",\"balancesend\",\"balance\",\"count_recv\",\"count_sent\",\"add_recv\",\"add_sent\",\\\n",
    "                        \"add_cnt1\",\"add_cnt2\",\"add_cnt3\",\"add_cnt4\",\"add_cnt5\",\"add_cnt6\",\\\n",
    "                        \"mot1_cnt1\",\"mot1_cnt2\",\"mot1_cnt3\",\"mot1_cnt4\",\"mot1_cnt5\",\"mot1_cnt6\",\\\n",
    "                        \"mot2_cnt1\",\"mot2_cnt2\",\"mot2_cnt3\",\"mot2_cnt4\",\"mot2_cnt5\",\"mot2_cnt6\")\n",
    "\n",
    "rf_final_y=df_final_rf.select(\"label\")\n",
    "\n",
    "#Round amount field\n",
    "rf_final_X = rf_final_X.withColumn(\"balancerecv\", f.round(rf_final_X[\"balancerecv\"], 6))\n",
    "rf_final_X = rf_final_X.withColumn(\"balancesend\", f.round(rf_final_X[\"balancesend\"], 6))\n",
    "rf_final_X = rf_final_X.withColumn(\"balance\", f.round(rf_final_X[\"balance\"], 6))\n",
    "\n",
    "#Transform input/output dataframe in vector\n",
    "rf_final_X_full= rf_final_X.fillna(0).collect()\n",
    "rf_final_y_full = rf_final_y.collect()\n",
    "\n",
    "#Reshape the output vector\n",
    "rf_final_y_full=np.reshape(rf_final_y_full,(len(rf_final_y_full),))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adaboost classifier\n",
    "cc=print_accuracy_report(\"ADA\", rf_final_X_full, rf_final_y_full,5)\n",
    "average_all(cc,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest classifier\n",
    "cc=print_accuracy_report(\"RFC\", rf_final_X_full, rf_final_y_full,5)\n",
    "average_all(cc,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#GB classifier\n",
    "#classifier= RandomForestClassifier(n_jobs=2, random_state=0)       \n",
    "#filename= '/home/titanium/spark_ml/final_rfc.pkl'\n",
    "#model=classifier.fit(rf_final_X_full,rf_final_y_full)\n",
    "#pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "cc=print_accuracy_report(\"GBC\",  rf_final_X_full, rf_final_y_full,5)\n",
    "average_all(cc,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_gbc = '/home/titanium/spark_ml/final_gbc.pkl'\n",
    "loaded_model_gbc_final = pickle.load(open(filename_gbc, 'rb'))\n",
    "\n",
    "filename_rfc = '/home/titanium/spark_ml/final_rfc.pkl'\n",
    "loaded_model_rfc_final = pickle.load(open(filename_rfc, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_feature = loaded_model_gbc_final.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_feature = loaded_model_rfc_final.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Definition\n",
    "# 1: exchange\n",
    "# 2: gambling\n",
    "# 3: market\n",
    "# 4: pool\n",
    "# 5: mixer\n",
    "# 6: service\n",
    "# 7: wallet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = (\"BTC recv\",\"BTC send\",\"balance\",\"tx recv\",\"tx sent\",\"#add recv\",\"#add sent\",\\\n",
    "                        \"add as Ex\",\"add as Gmb\",\"add as Mrk\",\"add as Pool\",\"add as Mxr\",\"add as Serv\",\\\n",
    "                        \"mot1 as Ex\",\"mot1 as Gmb\",\"mot1 as Mrk\",\"mot1 as Pool\",\"mot1 as Mxr\",\"mot1 as Serv\",\\\n",
    "                        \"mot2 as Ex\",\"mot2 as Gmb\",\"mot2 as Mrk\",\"mot2 as Pool\",\"mot2 as Mxr\",\"mot2 as Serv\")\n",
    "\n",
    "importance = pd.DataFrame(\n",
    "    {'feature': objects,\n",
    "     'score': gbc_feature\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance=importance.sort_values(\"score\",0,False)\n",
    "print(importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "importance2=importance.iloc[0:15]\n",
    "y_pos = np.arange(len(importance2))\n",
    "plt.bar(y_pos, importance2['score'], align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, importance2['feature'],rotation='vertical')\n",
    "plt.ylabel('Importance Score')\n",
    "plt.title('Feature Importance')\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/titanium/importance_score.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
